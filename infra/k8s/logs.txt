* 
* ==> Audit <==
* |---------|--------------------|----------|------|---------|-------------------------------|-------------------------------|
| Command |        Args        | Profile  | User | Version |          Start Time           |           End Time            |
|---------|--------------------|----------|------|---------|-------------------------------|-------------------------------|
| start   | --driver=none      | minikube | root | v1.24.0 | Mon, 08 Nov 2021 14:41:03 UTC | Mon, 08 Nov 2021 14:41:45 UTC |
| tunnel  |                    | minikube | root | v1.24.0 | Mon, 08 Nov 2021 15:33:13 UTC | Mon, 08 Nov 2021 15:34:28 UTC |
| ip      |                    | minikube | root | v1.24.0 | Mon, 08 Nov 2021 15:34:31 UTC | Mon, 08 Nov 2021 15:34:31 UTC |
| stop    |                    | minikube | root | v1.24.0 | Mon, 08 Nov 2021 15:46:33 UTC | Mon, 08 Nov 2021 15:46:44 UTC |
| start   |                    | minikube | root | v1.24.0 | Mon, 08 Nov 2021 15:47:03 UTC | Mon, 08 Nov 2021 15:47:22 UTC |
| ip      |                    | minikube | root | v1.24.0 | Mon, 08 Nov 2021 15:48:56 UTC | Mon, 08 Nov 2021 15:48:56 UTC |
| addons  | enable ingress     | minikube | root | v1.24.0 | Mon, 08 Nov 2021 15:58:24 UTC | Mon, 08 Nov 2021 15:58:41 UTC |
| stop    |                    | minikube | root | v1.24.0 | Mon, 08 Nov 2021 16:00:42 UTC | Mon, 08 Nov 2021 16:00:53 UTC |
| start   |                    | minikube | root | v1.24.0 | Mon, 08 Nov 2021 16:01:09 UTC | Mon, 08 Nov 2021 16:01:29 UTC |
| addons  |                    | minikube | root | v1.24.0 | Mon, 08 Nov 2021 16:08:53 UTC | Mon, 08 Nov 2021 16:08:53 UTC |
| addons  | list               | minikube | root | v1.24.0 | Mon, 08 Nov 2021 16:08:58 UTC | Mon, 08 Nov 2021 16:08:58 UTC |
| addons  | enable ingress     | minikube | root | v1.24.0 | Mon, 08 Nov 2021 16:09:19 UTC | Mon, 08 Nov 2021 16:09:19 UTC |
| addons  | enable ingress-dns | minikube | root | v1.24.0 | Mon, 08 Nov 2021 16:09:22 UTC | Mon, 08 Nov 2021 16:09:23 UTC |
| addons  | disable ingress    | minikube | root | v1.24.0 | Mon, 08 Nov 2021 16:10:12 UTC | Mon, 08 Nov 2021 16:10:57 UTC |
| addons  | enable ingress     | minikube | root | v1.24.0 | Mon, 08 Nov 2021 16:17:35 UTC | Mon, 08 Nov 2021 16:17:42 UTC |
| delete  |                    | minikube | root | v1.24.0 | Mon, 08 Nov 2021 18:30:42 UTC | Mon, 08 Nov 2021 18:31:30 UTC |
| start   | --driver=none      | minikube | root | v1.24.0 | Mon, 08 Nov 2021 19:39:39 UTC | Mon, 08 Nov 2021 19:40:01 UTC |
| addons  | enbable ingress    | minikube | root | v1.24.0 | Mon, 08 Nov 2021 19:40:27 UTC | Mon, 08 Nov 2021 19:40:27 UTC |
| addons  | enable ingress     | minikube | root | v1.24.0 | Mon, 08 Nov 2021 19:40:33 UTC | Mon, 08 Nov 2021 19:40:39 UTC |
| ip      |                    | minikube | root | v1.24.0 | Mon, 08 Nov 2021 19:42:39 UTC | Mon, 08 Nov 2021 19:42:40 UTC |
| addons  | list               | minikube | root | v1.24.0 | Mon, 08 Nov 2021 19:47:24 UTC | Mon, 08 Nov 2021 19:47:24 UTC |
| profile | list               | minikube | root | v1.24.0 | Mon, 08 Nov 2021 19:53:02 UTC | Mon, 08 Nov 2021 19:53:02 UTC |
| addons  | enable ingress     | minikube | root | v1.24.0 | Mon, 08 Nov 2021 19:54:36 UTC | Mon, 08 Nov 2021 19:54:36 UTC |
| tunnel  |                    | minikube | root | v1.24.0 | Mon, 08 Nov 2021 19:54:49 UTC | Mon, 08 Nov 2021 19:56:39 UTC |
| ip      |                    | minikube | root | v1.24.0 | Mon, 08 Nov 2021 19:57:22 UTC | Mon, 08 Nov 2021 19:57:22 UTC |
| ip      |                    | minikube | root | v1.24.0 | Mon, 08 Nov 2021 20:23:14 UTC | Mon, 08 Nov 2021 20:23:14 UTC |
| delete  |                    | minikube | root | v1.24.0 | Tue, 09 Nov 2021 09:35:51 UTC | Tue, 09 Nov 2021 09:36:36 UTC |
| start   | --driver=none      | minikube | root | v1.24.0 | Tue, 09 Nov 2021 11:03:12 UTC | Tue, 09 Nov 2021 11:03:33 UTC |
| ip      |                    | minikube | root | v1.24.0 | Tue, 09 Nov 2021 11:07:28 UTC | Tue, 09 Nov 2021 11:07:28 UTC |
|---------|--------------------|----------|------|---------|-------------------------------|-------------------------------|

* 
* ==> Last Start <==
* Log file created at: 2021/11/09 11:03:12
Running on machine: ubuntu-s-2vcpu-4gb-intel-fra1-01
Binary: Built with gc go1.17.2 for linux/amd64
Log line format: [IWEF]mmdd hh:mm:ss.uuuuuu threadid file:line] msg
I1109 11:03:12.135673 1054993 out.go:297] Setting OutFile to fd 1 ...
I1109 11:03:12.135790 1054993 out.go:349] isatty.IsTerminal(1) = true
I1109 11:03:12.135793 1054993 out.go:310] Setting ErrFile to fd 2...
I1109 11:03:12.135797 1054993 out.go:349] isatty.IsTerminal(2) = true
I1109 11:03:12.135891 1054993 root.go:313] Updating PATH: /root/.minikube/bin
I1109 11:03:12.136439 1054993 out.go:304] Setting JSON to false
I1109 11:03:12.137480 1054993 start.go:112] hostinfo: {"hostname":"ubuntu-s-2vcpu-4gb-intel-fra1-01","uptime":257375,"bootTime":1636198418,"procs":157,"os":"linux","platform":"ubuntu","platformFamily":"debian","platformVersion":"20.04","kernelVersion":"5.4.0-88-generic","kernelArch":"x86_64","virtualizationSystem":"kvm","virtualizationRole":"guest","hostId":"8173f7e2-6bcc-45db-a85e-6d87c4576d14"}
I1109 11:03:12.137592 1054993 start.go:122] virtualization: kvm guest
I1109 11:03:12.139837 1054993 out.go:176] üòÑ  minikube v1.24.0 on Ubuntu 20.04 (kvm/amd64)
W1109 11:03:12.140097 1054993 preload.go:294] Failed to list preload files: open /root/.minikube/cache/preloaded-tarball: no such file or directory
I1109 11:03:12.140215 1054993 notify.go:174] Checking for updates...
I1109 11:03:12.140298 1054993 driver.go:343] Setting default libvirt URI to qemu:///system
I1109 11:03:12.141280 1054993 out.go:176] ‚ú®  Using the none driver based on user configuration
I1109 11:03:12.141308 1054993 start.go:280] selected driver: none
I1109 11:03:12.141312 1054993 start.go:762] validating driver "none" against <nil>
I1109 11:03:12.141325 1054993 start.go:773] status for none: {Installed:true Healthy:true Running:false NeedsImprovement:false Error:<nil> Reason: Fix: Doc:}
I1109 11:03:12.141361 1054993 start.go:1447] auto setting extra-config to "kubelet.resolv-conf=/run/systemd/resolve/resolv.conf".
I1109 11:03:12.141508 1054993 start_flags.go:268] no existing cluster config was found, will generate one from the flags 
I1109 11:03:12.141734 1054993 start_flags.go:349] Using suggested 2200MB memory alloc based on sys=3936MB, container=0MB
I1109 11:03:12.141818 1054993 start_flags.go:736] Wait components to verify : map[apiserver:true system_pods:true]
I1109 11:03:12.141831 1054993 cni.go:93] Creating CNI manager for ""
I1109 11:03:12.141840 1054993 cni.go:147] Driver none used, CNI unnecessary in this configuration, recommending no CNI
I1109 11:03:12.141844 1054993 start_flags.go:282] config:
{Name:minikube KeepContext:false EmbedCerts:false MinikubeISO: KicBaseImage:gcr.io/k8s-minikube/kicbase:v0.0.28@sha256:4780f1897569d2bf77aafb3d133a08d42b4fe61127f06fcfc90c2c5d902d893c Memory:2200 CPUs:2 DiskSize:20000 VMDriver: Driver:none HyperkitVpnKitSock: HyperkitVSockPorts:[] DockerEnv:[] ContainerVolumeMounts:[] InsecureRegistry:[] RegistryMirror:[] HostOnlyCIDR:192.168.59.1/24 HypervVirtualSwitch: HypervUseExternalSwitch:false HypervExternalAdapter: KVMNetwork:default KVMQemuURI:qemu:///system KVMGPU:false KVMHidden:false KVMNUMACount:1 DockerOpt:[] DisableDriverMounts:false NFSShare:[] NFSSharesRoot:/nfsshares UUID: NoVTXCheck:false DNSProxy:false HostDNSResolver:true HostOnlyNicType:virtio NatNicType:virtio SSHIPAddress: SSHUser:root SSHKey: SSHPort:22 KubernetesConfig:{KubernetesVersion:v1.22.3 ClusterName:minikube Namespace:default APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin: FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: LoadBalancerStartIP: LoadBalancerEndIP: CustomIngressCert: ExtraOptions:[{Component:kubelet Key:resolv-conf Value:/run/systemd/resolve/resolv.conf}] ShouldLoadCachedImages:false EnableDefaultCNI:false CNI: NodeIP: NodePort:8443 NodeName:} Nodes:[] Addons:map[] CustomAddonImages:map[] CustomAddonRegistries:map[] VerifyComponents:map[apiserver:true system_pods:true] StartHostTimeout:6m0s ScheduledStop:<nil> ExposedPorts:[] ListenAddress: Network: MultiNodeRequested:false ExtraDisks:0 CertExpiration:26280h0m0s Mount:false MountString:/root:/minikube-host}
I1109 11:03:12.143252 1054993 out.go:176] üëç  Starting control plane node minikube in cluster minikube
I1109 11:03:12.143620 1054993 profile.go:147] Saving config to /root/.minikube/profiles/minikube/config.json ...
I1109 11:03:12.143651 1054993 lock.go:35] WriteFile acquiring /root/.minikube/profiles/minikube/config.json: {Name:mk270d1b5db5965f2dc9e9e25770a63417031943 Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
I1109 11:03:12.145779 1054993 cache.go:206] Successfully downloaded all kic artifacts
I1109 11:03:12.145817 1054993 start.go:313] acquiring machines lock for minikube: {Name:mkc8ab01ad3ea83211c505c81a7ee49a8e3ecb89 Clock:{} Delay:500ms Timeout:13m0s Cancel:<nil>}
I1109 11:03:12.145881 1054993 start.go:317] acquired machines lock for "minikube" in 51.937¬µs
I1109 11:03:12.145891 1054993 start.go:89] Provisioning new machine with config: &{Name:minikube KeepContext:false EmbedCerts:false MinikubeISO: KicBaseImage:gcr.io/k8s-minikube/kicbase:v0.0.28@sha256:4780f1897569d2bf77aafb3d133a08d42b4fe61127f06fcfc90c2c5d902d893c Memory:2200 CPUs:2 DiskSize:20000 VMDriver: Driver:none HyperkitVpnKitSock: HyperkitVSockPorts:[] DockerEnv:[] ContainerVolumeMounts:[] InsecureRegistry:[] RegistryMirror:[] HostOnlyCIDR:192.168.59.1/24 HypervVirtualSwitch: HypervUseExternalSwitch:false HypervExternalAdapter: KVMNetwork:default KVMQemuURI:qemu:///system KVMGPU:false KVMHidden:false KVMNUMACount:1 DockerOpt:[] DisableDriverMounts:false NFSShare:[] NFSSharesRoot:/nfsshares UUID: NoVTXCheck:false DNSProxy:false HostDNSResolver:true HostOnlyNicType:virtio NatNicType:virtio SSHIPAddress: SSHUser:root SSHKey: SSHPort:22 KubernetesConfig:{KubernetesVersion:v1.22.3 ClusterName:minikube Namespace:default APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin: FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: LoadBalancerStartIP: LoadBalancerEndIP: CustomIngressCert: ExtraOptions:[{Component:kubelet Key:resolv-conf Value:/run/systemd/resolve/resolv.conf}] ShouldLoadCachedImages:false EnableDefaultCNI:false CNI: NodeIP: NodePort:8443 NodeName:} Nodes:[{Name:m01 IP: Port:8443 KubernetesVersion:v1.22.3 ControlPlane:true Worker:true}] Addons:map[] CustomAddonImages:map[] CustomAddonRegistries:map[] VerifyComponents:map[apiserver:true system_pods:true] StartHostTimeout:6m0s ScheduledStop:<nil> ExposedPorts:[] ListenAddress: Network: MultiNodeRequested:false ExtraDisks:0 CertExpiration:26280h0m0s Mount:false MountString:/root:/minikube-host} &{Name:m01 IP: Port:8443 KubernetesVersion:v1.22.3 ControlPlane:true Worker:true}
I1109 11:03:12.145977 1054993 start.go:126] createHost starting for "m01" (driver="none")
I1109 11:03:12.147116 1054993 out.go:176] ü§π  Running on localhost (CPUs=2, Memory=3936MB, Disk=79219MB) ...
I1109 11:03:12.147227 1054993 exec_runner.go:51] Run: systemctl --version
I1109 11:03:12.150786 1054993 start.go:160] libmachine.API.Create for "minikube" (driver="none")
I1109 11:03:12.150888 1054993 client.go:168] LocalClient.Create starting
I1109 11:03:12.150983 1054993 main.go:130] libmachine: Reading certificate data from /root/.minikube/certs/ca.pem
I1109 11:03:12.151005 1054993 main.go:130] libmachine: Decoding PEM data...
I1109 11:03:12.151020 1054993 main.go:130] libmachine: Parsing certificate...
I1109 11:03:12.151104 1054993 main.go:130] libmachine: Reading certificate data from /root/.minikube/certs/cert.pem
I1109 11:03:12.151139 1054993 main.go:130] libmachine: Decoding PEM data...
I1109 11:03:12.151150 1054993 main.go:130] libmachine: Parsing certificate...
I1109 11:03:12.151516 1054993 client.go:171] LocalClient.Create took 620.73¬µs
I1109 11:03:12.151536 1054993 start.go:168] duration metric: libmachine.API.Create for "minikube" took 756.009¬µs
I1109 11:03:12.151540 1054993 start.go:267] post-start starting for "minikube" (driver="none")
I1109 11:03:12.151543 1054993 start.go:277] creating required directories: [/etc/kubernetes/addons /etc/kubernetes/manifests /var/tmp/minikube /var/lib/minikube /var/lib/minikube/certs /var/lib/minikube/images /var/lib/minikube/binaries /tmp/gvisor /usr/share/ca-certificates /etc/ssl/certs]
I1109 11:03:12.151583 1054993 exec_runner.go:51] Run: sudo mkdir -p /etc/kubernetes/addons /etc/kubernetes/manifests /var/tmp/minikube /var/lib/minikube /var/lib/minikube/certs /var/lib/minikube/images /var/lib/minikube/binaries /tmp/gvisor /usr/share/ca-certificates /etc/ssl/certs
I1109 11:03:12.175413 1054993 main.go:130] libmachine: Couldn't set key PRIVACY_POLICY_URL, no corresponding struct field found
I1109 11:03:12.175440 1054993 main.go:130] libmachine: Couldn't set key VERSION_CODENAME, no corresponding struct field found
I1109 11:03:12.175452 1054993 main.go:130] libmachine: Couldn't set key UBUNTU_CODENAME, no corresponding struct field found
I1109 11:03:12.178300 1054993 out.go:176] ‚ÑπÔ∏è  OS release is Ubuntu 20.04.3 LTS
I1109 11:03:12.178355 1054993 filesync.go:126] Scanning /root/.minikube/addons for local assets ...
I1109 11:03:12.178419 1054993 filesync.go:126] Scanning /root/.minikube/files for local assets ...
I1109 11:03:12.178437 1054993 start.go:270] post-start completed in 26.892022ms
I1109 11:03:12.179369 1054993 profile.go:147] Saving config to /root/.minikube/profiles/minikube/config.json ...
I1109 11:03:12.179546 1054993 start.go:129] duration metric: createHost completed in 33.557448ms
I1109 11:03:12.179557 1054993 start.go:80] releasing machines lock for "minikube", held for 33.669405ms
I1109 11:03:12.180056 1054993 exec_runner.go:51] Run: sudo systemctl is-active --quiet service containerd
I1109 11:03:12.180989 1054993 exec_runner.go:51] Run: curl -sS -m 2 https://k8s.gcr.io/
I1109 11:03:12.197792 1054993 exec_runner.go:51] Run: /bin/bash -c "sudo mkdir -p /etc && printf %!s(MISSING) "runtime-endpoint: unix:///var/run/dockershim.sock
image-endpoint: unix:///var/run/dockershim.sock
" | sudo tee /etc/crictl.yaml"
I1109 11:03:12.222925 1054993 exec_runner.go:51] Run: sudo systemctl unmask docker.service
I1109 11:03:12.526459 1054993 exec_runner.go:51] Run: sudo systemctl enable docker.socket
I1109 11:03:12.824560 1054993 exec_runner.go:51] Run: sudo systemctl cat docker.service
I1109 11:03:12.836584 1054993 exec_runner.go:51] Run: sudo systemctl daemon-reload
I1109 11:03:13.125197 1054993 exec_runner.go:51] Run: sudo systemctl restart docker
I1109 11:03:13.704715 1054993 exec_runner.go:51] Run: docker version --format {{.Server.Version}}
I1109 11:03:13.764112 1054993 exec_runner.go:51] Run: docker version --format {{.Server.Version}}
I1109 11:03:13.826031 1054993 out.go:203] üê≥  Preparing Kubernetes v1.22.3 on Docker 20.10.10 ...
I1109 11:03:13.826147 1054993 exec_runner.go:51] Run: grep 127.0.0.1	host.minikube.internal$ /etc/hosts
I1109 11:03:13.828672 1054993 out.go:176]     ‚ñ™ kubelet.resolv-conf=/run/systemd/resolve/resolv.conf
I1109 11:03:13.829135 1054993 preload.go:132] Checking if preload exists for k8s version v1.22.3 and runtime docker
I1109 11:03:13.829183 1054993 exec_runner.go:51] Run: docker info --format {{.CgroupDriver}}
I1109 11:03:13.956429 1054993 cni.go:93] Creating CNI manager for ""
I1109 11:03:13.956443 1054993 cni.go:147] Driver none used, CNI unnecessary in this configuration, recommending no CNI
I1109 11:03:13.956455 1054993 kubeadm.go:87] Using pod CIDR: 10.244.0.0/16
I1109 11:03:13.956473 1054993 kubeadm.go:153] kubeadm options: {CertDir:/var/lib/minikube/certs ServiceCIDR:10.96.0.0/12 PodSubnet:10.244.0.0/16 AdvertiseAddress:207.154.254.97 APIServerPort:8443 KubernetesVersion:v1.22.3 EtcdDataDir:/var/lib/minikube/etcd EtcdExtraArgs:map[] ClusterName:minikube NodeName:ubuntu-s-2vcpu-4gb-intel-fra1-01 DNSDomain:cluster.local CRISocket:/var/run/dockershim.sock ImageRepository: ComponentOptions:[{Component:apiServer ExtraArgs:map[enable-admission-plugins:NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,DefaultTolerationSeconds,NodeRestriction,MutatingAdmissionWebhook,ValidatingAdmissionWebhook,ResourceQuota] Pairs:map[certSANs:["127.0.0.1", "localhost", "207.154.254.97"]]} {Component:controllerManager ExtraArgs:map[allocate-node-cidrs:true leader-elect:false] Pairs:map[]} {Component:scheduler ExtraArgs:map[leader-elect:false] Pairs:map[]}] FeatureArgs:map[] NoTaintMaster:true NodeIP:207.154.254.97 CgroupDriver:cgroupfs ClientCAFile:/var/lib/minikube/certs/ca.crt StaticPodPath:/etc/kubernetes/manifests ControlPlaneAddress:control-plane.minikube.internal KubeProxyOptions:map[]}
I1109 11:03:13.956665 1054993 kubeadm.go:157] kubeadm config:
apiVersion: kubeadm.k8s.io/v1beta2
kind: InitConfiguration
localAPIEndpoint:
  advertiseAddress: 207.154.254.97
  bindPort: 8443
bootstrapTokens:
  - groups:
      - system:bootstrappers:kubeadm:default-node-token
    ttl: 24h0m0s
    usages:
      - signing
      - authentication
nodeRegistration:
  criSocket: /var/run/dockershim.sock
  name: "ubuntu-s-2vcpu-4gb-intel-fra1-01"
  kubeletExtraArgs:
    node-ip: 207.154.254.97
  taints: []
---
apiVersion: kubeadm.k8s.io/v1beta2
kind: ClusterConfiguration
apiServer:
  certSANs: ["127.0.0.1", "localhost", "207.154.254.97"]
  extraArgs:
    enable-admission-plugins: "NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,DefaultTolerationSeconds,NodeRestriction,MutatingAdmissionWebhook,ValidatingAdmissionWebhook,ResourceQuota"
controllerManager:
  extraArgs:
    allocate-node-cidrs: "true"
    leader-elect: "false"
scheduler:
  extraArgs:
    leader-elect: "false"
certificatesDir: /var/lib/minikube/certs
clusterName: mk
controlPlaneEndpoint: control-plane.minikube.internal:8443
dns:
  type: CoreDNS
etcd:
  local:
    dataDir: /var/lib/minikube/etcd
    extraArgs:
      proxy-refresh-interval: "70000"
kubernetesVersion: v1.22.3
networking:
  dnsDomain: cluster.local
  podSubnet: "10.244.0.0/16"
  serviceSubnet: 10.96.0.0/12
---
apiVersion: kubelet.config.k8s.io/v1beta1
kind: KubeletConfiguration
authentication:
  x509:
    clientCAFile: /var/lib/minikube/certs/ca.crt
cgroupDriver: cgroupfs
clusterDomain: "cluster.local"
# disable disk resource management by default
imageGCHighThresholdPercent: 100
evictionHard:
  nodefs.available: "0%!"(MISSING)
  nodefs.inodesFree: "0%!"(MISSING)
  imagefs.available: "0%!"(MISSING)
failSwapOn: false
staticPodPath: /etc/kubernetes/manifests
---
apiVersion: kubeproxy.config.k8s.io/v1alpha1
kind: KubeProxyConfiguration
clusterCIDR: "10.244.0.0/16"
metricsBindAddress: 0.0.0.0:10249
conntrack:
  maxPerCore: 0
# Skip setting "net.netfilter.nf_conntrack_tcp_timeout_established"
  tcpEstablishedTimeout: 0s
# Skip setting "net.netfilter.nf_conntrack_tcp_timeout_close"
  tcpCloseWaitTimeout: 0s

I1109 11:03:13.956812 1054993 kubeadm.go:909] kubelet [Unit]
Wants=docker.socket

[Service]
ExecStart=
ExecStart=/var/lib/minikube/binaries/v1.22.3/kubelet --bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kubelet.conf --config=/var/lib/kubelet/config.yaml --container-runtime=docker --hostname-override=ubuntu-s-2vcpu-4gb-intel-fra1-01 --kubeconfig=/etc/kubernetes/kubelet.conf --node-ip=207.154.254.97 --resolv-conf=/run/systemd/resolve/resolv.conf

[Install]
 config:
{KubernetesVersion:v1.22.3 ClusterName:minikube Namespace:default APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin: FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: LoadBalancerStartIP: LoadBalancerEndIP: CustomIngressCert: ExtraOptions:[{Component:kubelet Key:resolv-conf Value:/run/systemd/resolve/resolv.conf}] ShouldLoadCachedImages:false EnableDefaultCNI:false CNI: NodeIP: NodePort:8443 NodeName:}
I1109 11:03:13.956884 1054993 exec_runner.go:51] Run: sudo ls /var/lib/minikube/binaries/v1.22.3
I1109 11:03:13.966428 1054993 binaries.go:47] Didn't find k8s binaries: sudo ls /var/lib/minikube/binaries/v1.22.3: exit status 2
stdout:

stderr:
ls: cannot access '/var/lib/minikube/binaries/v1.22.3': No such file or directory

Initiating transfer...
I1109 11:03:13.966481 1054993 exec_runner.go:51] Run: sudo mkdir -p /var/lib/minikube/binaries/v1.22.3
I1109 11:03:13.976731 1054993 binary.go:67] Not caching binary, using https://storage.googleapis.com/kubernetes-release/release/v1.22.3/bin/linux/amd64/kubelet?checksum=file:https://storage.googleapis.com/kubernetes-release/release/v1.22.3/bin/linux/amd64/kubelet.sha256
I1109 11:03:13.976748 1054993 binary.go:67] Not caching binary, using https://storage.googleapis.com/kubernetes-release/release/v1.22.3/bin/linux/amd64/kubeadm?checksum=file:https://storage.googleapis.com/kubernetes-release/release/v1.22.3/bin/linux/amd64/kubeadm.sha256
I1109 11:03:13.976790 1054993 exec_runner.go:51] Run: sudo systemctl is-active --quiet service kubelet
I1109 11:03:13.976803 1054993 exec_runner.go:151] cp: /root/.minikube/cache/linux/v1.22.3/kubeadm --> /var/lib/minikube/binaries/v1.22.3/kubeadm (45838336 bytes)
I1109 11:03:13.977225 1054993 binary.go:67] Not caching binary, using https://storage.googleapis.com/kubernetes-release/release/v1.22.3/bin/linux/amd64/kubectl?checksum=file:https://storage.googleapis.com/kubernetes-release/release/v1.22.3/bin/linux/amd64/kubectl.sha256
I1109 11:03:13.977275 1054993 exec_runner.go:151] cp: /root/.minikube/cache/linux/v1.22.3/kubectl --> /var/lib/minikube/binaries/v1.22.3/kubectl (46907392 bytes)
I1109 11:03:13.995785 1054993 exec_runner.go:151] cp: /root/.minikube/cache/linux/v1.22.3/kubelet --> /var/lib/minikube/binaries/v1.22.3/kubelet (121180280 bytes)
I1109 11:03:14.165204 1054993 exec_runner.go:51] Run: sudo cp -a /tmp/minikube1387319151 /var/lib/minikube/binaries/v1.22.3/kubeadm
I1109 11:03:14.197637 1054993 exec_runner.go:51] Run: sudo cp -a /tmp/minikube2605272130 /var/lib/minikube/binaries/v1.22.3/kubectl
I1109 11:03:14.417764 1054993 exec_runner.go:51] Run: sudo cp -a /tmp/minikube2408739083 /var/lib/minikube/binaries/v1.22.3/kubelet
I1109 11:03:14.532975 1054993 exec_runner.go:51] Run: sudo mkdir -p /etc/systemd/system/kubelet.service.d /lib/systemd/system /var/tmp/minikube
I1109 11:03:14.540522 1054993 exec_runner.go:144] found /etc/systemd/system/kubelet.service.d/10-kubeadm.conf, removing ...
I1109 11:03:14.540537 1054993 exec_runner.go:207] rm: /etc/systemd/system/kubelet.service.d/10-kubeadm.conf
I1109 11:03:14.540600 1054993 exec_runner.go:151] cp: memory --> /etc/systemd/system/kubelet.service.d/10-kubeadm.conf (407 bytes)
I1109 11:03:14.540732 1054993 exec_runner.go:51] Run: sudo cp -a /tmp/minikube920169416 /etc/systemd/system/kubelet.service.d/10-kubeadm.conf
I1109 11:03:14.549780 1054993 exec_runner.go:144] found /lib/systemd/system/kubelet.service, removing ...
I1109 11:03:14.549797 1054993 exec_runner.go:207] rm: /lib/systemd/system/kubelet.service
I1109 11:03:14.561123 1054993 exec_runner.go:151] cp: memory --> /lib/systemd/system/kubelet.service (352 bytes)
I1109 11:03:14.561322 1054993 exec_runner.go:51] Run: sudo cp -a /tmp/minikube241767318 /lib/systemd/system/kubelet.service
I1109 11:03:14.575292 1054993 exec_runner.go:151] cp: memory --> /var/tmp/minikube/kubeadm.yaml.new (2081 bytes)
I1109 11:03:14.575452 1054993 exec_runner.go:51] Run: sudo cp -a /tmp/minikube584172454 /var/tmp/minikube/kubeadm.yaml.new
I1109 11:03:14.588963 1054993 exec_runner.go:51] Run: grep 207.154.254.97	control-plane.minikube.internal$ /etc/hosts
I1109 11:03:14.590807 1054993 certs.go:54] Setting up /root/.minikube/profiles/minikube for IP: 207.154.254.97
I1109 11:03:14.590903 1054993 certs.go:182] skipping minikubeCA CA generation: /root/.minikube/ca.key
I1109 11:03:14.590943 1054993 certs.go:182] skipping proxyClientCA CA generation: /root/.minikube/proxy-client-ca.key
I1109 11:03:14.590995 1054993 certs.go:302] generating minikube-user signed cert: /root/.minikube/profiles/minikube/client.key
I1109 11:03:14.591006 1054993 crypto.go:68] Generating cert /root/.minikube/profiles/minikube/client.crt with IP's: []
I1109 11:03:15.218562 1054993 crypto.go:156] Writing cert to /root/.minikube/profiles/minikube/client.crt ...
I1109 11:03:15.218583 1054993 lock.go:35] WriteFile acquiring /root/.minikube/profiles/minikube/client.crt: {Name:mk09878e812b07af637940656ec44996daba95aa Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
I1109 11:03:15.218795 1054993 crypto.go:164] Writing key to /root/.minikube/profiles/minikube/client.key ...
I1109 11:03:15.218801 1054993 lock.go:35] WriteFile acquiring /root/.minikube/profiles/minikube/client.key: {Name:mkf3b978f9858871583d8228f83a87a85b7d106f Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
I1109 11:03:15.218873 1054993 certs.go:302] generating minikube signed cert: /root/.minikube/profiles/minikube/apiserver.key.8fb2ae24
I1109 11:03:15.218882 1054993 crypto.go:68] Generating cert /root/.minikube/profiles/minikube/apiserver.crt.8fb2ae24 with IP's: [207.154.254.97 10.96.0.1 127.0.0.1 10.0.0.1]
I1109 11:03:15.324734 1054993 crypto.go:156] Writing cert to /root/.minikube/profiles/minikube/apiserver.crt.8fb2ae24 ...
I1109 11:03:15.324751 1054993 lock.go:35] WriteFile acquiring /root/.minikube/profiles/minikube/apiserver.crt.8fb2ae24: {Name:mk173379eacd6f87239e95e6a4e4e7fa635c1cb4 Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
I1109 11:03:15.324943 1054993 crypto.go:164] Writing key to /root/.minikube/profiles/minikube/apiserver.key.8fb2ae24 ...
I1109 11:03:15.324949 1054993 lock.go:35] WriteFile acquiring /root/.minikube/profiles/minikube/apiserver.key.8fb2ae24: {Name:mkece4b53d780ccaa660e9d9c890e4c2c86f14fe Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
I1109 11:03:15.325040 1054993 certs.go:320] copying /root/.minikube/profiles/minikube/apiserver.crt.8fb2ae24 -> /root/.minikube/profiles/minikube/apiserver.crt
I1109 11:03:15.325101 1054993 certs.go:324] copying /root/.minikube/profiles/minikube/apiserver.key.8fb2ae24 -> /root/.minikube/profiles/minikube/apiserver.key
I1109 11:03:15.325146 1054993 certs.go:302] generating aggregator signed cert: /root/.minikube/profiles/minikube/proxy-client.key
I1109 11:03:15.325157 1054993 crypto.go:68] Generating cert /root/.minikube/profiles/minikube/proxy-client.crt with IP's: []
I1109 11:03:16.010371 1054993 crypto.go:156] Writing cert to /root/.minikube/profiles/minikube/proxy-client.crt ...
I1109 11:03:16.010393 1054993 lock.go:35] WriteFile acquiring /root/.minikube/profiles/minikube/proxy-client.crt: {Name:mkcab3ddb18cd096d978df14d87a44e804896057 Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
I1109 11:03:16.010609 1054993 crypto.go:164] Writing key to /root/.minikube/profiles/minikube/proxy-client.key ...
I1109 11:03:16.010615 1054993 lock.go:35] WriteFile acquiring /root/.minikube/profiles/minikube/proxy-client.key: {Name:mkaff5bf6f623f02423597918f5f33c2a99a3db1 Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
I1109 11:03:16.010754 1054993 certs.go:388] found cert: /root/.minikube/certs/root/.minikube/certs/ca-key.pem (1675 bytes)
I1109 11:03:16.011080 1054993 certs.go:388] found cert: /root/.minikube/certs/root/.minikube/certs/ca.pem (1070 bytes)
I1109 11:03:16.011104 1054993 certs.go:388] found cert: /root/.minikube/certs/root/.minikube/certs/cert.pem (1115 bytes)
I1109 11:03:16.011151 1054993 certs.go:388] found cert: /root/.minikube/certs/root/.minikube/certs/key.pem (1675 bytes)
I1109 11:03:16.012287 1054993 exec_runner.go:151] cp: /root/.minikube/profiles/minikube/apiserver.crt --> /var/lib/minikube/certs/apiserver.crt (1399 bytes)
I1109 11:03:16.012415 1054993 exec_runner.go:51] Run: sudo cp -a /tmp/minikube1185149762 /var/lib/minikube/certs/apiserver.crt
I1109 11:03:16.021770 1054993 exec_runner.go:151] cp: /root/.minikube/profiles/minikube/apiserver.key --> /var/lib/minikube/certs/apiserver.key (1675 bytes)
I1109 11:03:16.021903 1054993 exec_runner.go:51] Run: sudo cp -a /tmp/minikube1169860764 /var/lib/minikube/certs/apiserver.key
I1109 11:03:16.030337 1054993 exec_runner.go:151] cp: /root/.minikube/profiles/minikube/proxy-client.crt --> /var/lib/minikube/certs/proxy-client.crt (1147 bytes)
I1109 11:03:16.030465 1054993 exec_runner.go:51] Run: sudo cp -a /tmp/minikube7243127 /var/lib/minikube/certs/proxy-client.crt
I1109 11:03:16.039624 1054993 exec_runner.go:151] cp: /root/.minikube/profiles/minikube/proxy-client.key --> /var/lib/minikube/certs/proxy-client.key (1675 bytes)
I1109 11:03:16.039742 1054993 exec_runner.go:51] Run: sudo cp -a /tmp/minikube1678570959 /var/lib/minikube/certs/proxy-client.key
I1109 11:03:16.048524 1054993 exec_runner.go:151] cp: /root/.minikube/ca.crt --> /var/lib/minikube/certs/ca.crt (1111 bytes)
I1109 11:03:16.048671 1054993 exec_runner.go:51] Run: sudo cp -a /tmp/minikube3510334238 /var/lib/minikube/certs/ca.crt
I1109 11:03:16.057836 1054993 exec_runner.go:151] cp: /root/.minikube/ca.key --> /var/lib/minikube/certs/ca.key (1675 bytes)
I1109 11:03:16.057986 1054993 exec_runner.go:51] Run: sudo cp -a /tmp/minikube3925634510 /var/lib/minikube/certs/ca.key
I1109 11:03:16.065303 1054993 exec_runner.go:151] cp: /root/.minikube/proxy-client-ca.crt --> /var/lib/minikube/certs/proxy-client-ca.crt (1119 bytes)
I1109 11:03:16.065471 1054993 exec_runner.go:51] Run: sudo cp -a /tmp/minikube1046269589 /var/lib/minikube/certs/proxy-client-ca.crt
I1109 11:03:16.075539 1054993 exec_runner.go:151] cp: /root/.minikube/proxy-client-ca.key --> /var/lib/minikube/certs/proxy-client-ca.key (1679 bytes)
I1109 11:03:16.075650 1054993 exec_runner.go:51] Run: sudo cp -a /tmp/minikube3022834111 /var/lib/minikube/certs/proxy-client-ca.key
I1109 11:03:16.084171 1054993 exec_runner.go:144] found /usr/share/ca-certificates/minikubeCA.pem, removing ...
I1109 11:03:16.084186 1054993 exec_runner.go:207] rm: /usr/share/ca-certificates/minikubeCA.pem
I1109 11:03:16.085008 1054993 exec_runner.go:151] cp: /root/.minikube/ca.crt --> /usr/share/ca-certificates/minikubeCA.pem (1111 bytes)
I1109 11:03:16.085162 1054993 exec_runner.go:51] Run: sudo cp -a /tmp/minikube3847734327 /usr/share/ca-certificates/minikubeCA.pem
I1109 11:03:16.095072 1054993 exec_runner.go:151] cp: memory --> /var/lib/minikube/kubeconfig (744 bytes)
I1109 11:03:16.095349 1054993 exec_runner.go:51] Run: sudo cp -a /tmp/minikube3340124001 /var/lib/minikube/kubeconfig
I1109 11:03:16.104611 1054993 exec_runner.go:51] Run: openssl version
I1109 11:03:16.110893 1054993 exec_runner.go:51] Run: sudo /bin/bash -c "test -s /usr/share/ca-certificates/minikubeCA.pem && ln -fs /usr/share/ca-certificates/minikubeCA.pem /etc/ssl/certs/minikubeCA.pem"
I1109 11:03:16.121112 1054993 exec_runner.go:51] Run: ls -la /usr/share/ca-certificates/minikubeCA.pem
I1109 11:03:16.123210 1054993 certs.go:431] hashing: -rw-r--r-- 1 root root 1111 Nov  9 11:03 /usr/share/ca-certificates/minikubeCA.pem
I1109 11:03:16.123266 1054993 exec_runner.go:51] Run: openssl x509 -hash -noout -in /usr/share/ca-certificates/minikubeCA.pem
I1109 11:03:16.128097 1054993 exec_runner.go:51] Run: sudo /bin/bash -c "test -L /etc/ssl/certs/b5213941.0 || ln -fs /etc/ssl/certs/minikubeCA.pem /etc/ssl/certs/b5213941.0"
I1109 11:03:16.137955 1054993 kubeadm.go:390] StartCluster: {Name:minikube KeepContext:false EmbedCerts:false MinikubeISO: KicBaseImage:gcr.io/k8s-minikube/kicbase:v0.0.28@sha256:4780f1897569d2bf77aafb3d133a08d42b4fe61127f06fcfc90c2c5d902d893c Memory:2200 CPUs:2 DiskSize:20000 VMDriver: Driver:none HyperkitVpnKitSock: HyperkitVSockPorts:[] DockerEnv:[] ContainerVolumeMounts:[] InsecureRegistry:[] RegistryMirror:[] HostOnlyCIDR:192.168.59.1/24 HypervVirtualSwitch: HypervUseExternalSwitch:false HypervExternalAdapter: KVMNetwork:default KVMQemuURI:qemu:///system KVMGPU:false KVMHidden:false KVMNUMACount:1 DockerOpt:[] DisableDriverMounts:false NFSShare:[] NFSSharesRoot:/nfsshares UUID: NoVTXCheck:false DNSProxy:false HostDNSResolver:true HostOnlyNicType:virtio NatNicType:virtio SSHIPAddress: SSHUser:root SSHKey: SSHPort:22 KubernetesConfig:{KubernetesVersion:v1.22.3 ClusterName:minikube Namespace:default APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin: FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: LoadBalancerStartIP: LoadBalancerEndIP: CustomIngressCert: ExtraOptions:[{Component:kubelet Key:resolv-conf Value:/run/systemd/resolve/resolv.conf}] ShouldLoadCachedImages:false EnableDefaultCNI:false CNI: NodeIP: NodePort:8443 NodeName:} Nodes:[{Name:m01 IP:207.154.254.97 Port:8443 KubernetesVersion:v1.22.3 ControlPlane:true Worker:true}] Addons:map[] CustomAddonImages:map[] CustomAddonRegistries:map[] VerifyComponents:map[apiserver:true system_pods:true] StartHostTimeout:6m0s ScheduledStop:<nil> ExposedPorts:[] ListenAddress: Network: MultiNodeRequested:false ExtraDisks:0 CertExpiration:26280h0m0s Mount:false MountString:/root:/minikube-host}
I1109 11:03:16.138129 1054993 exec_runner.go:51] Run: docker ps --filter status=paused --filter=name=k8s_.*_(kube-system)_ --format={{.ID}}
I1109 11:03:16.183997 1054993 exec_runner.go:51] Run: sudo ls /var/lib/kubelet/kubeadm-flags.env /var/lib/kubelet/config.yaml /var/lib/minikube/etcd
I1109 11:03:16.192648 1054993 exec_runner.go:51] Run: sudo cp /var/tmp/minikube/kubeadm.yaml.new /var/tmp/minikube/kubeadm.yaml
I1109 11:03:16.201934 1054993 exec_runner.go:51] Run: docker version --format {{.Server.Version}}
I1109 11:03:16.253192 1054993 exec_runner.go:51] Run: sudo ls -la /etc/kubernetes/admin.conf /etc/kubernetes/kubelet.conf /etc/kubernetes/controller-manager.conf /etc/kubernetes/scheduler.conf
I1109 11:03:16.262546 1054993 kubeadm.go:151] config check failed, skipping stale config cleanup: sudo ls -la /etc/kubernetes/admin.conf /etc/kubernetes/kubelet.conf /etc/kubernetes/controller-manager.conf /etc/kubernetes/scheduler.conf: exit status 2
stdout:

stderr:
ls: cannot access '/etc/kubernetes/admin.conf': No such file or directory
ls: cannot access '/etc/kubernetes/kubelet.conf': No such file or directory
ls: cannot access '/etc/kubernetes/controller-manager.conf': No such file or directory
ls: cannot access '/etc/kubernetes/scheduler.conf': No such file or directory
I1109 11:03:16.262603 1054993 exec_runner.go:97] Start: /bin/bash -c "sudo env PATH="/var/lib/minikube/binaries/v1.22.3:$PATH" kubeadm init --config /var/tmp/minikube/kubeadm.yaml  --ignore-preflight-errors=DirAvailable--etc-kubernetes-manifests,DirAvailable--var-lib-minikube,DirAvailable--var-lib-minikube-etcd,FileAvailable--etc-kubernetes-manifests-kube-scheduler.yaml,FileAvailable--etc-kubernetes-manifests-kube-apiserver.yaml,FileAvailable--etc-kubernetes-manifests-kube-controller-manager.yaml,FileAvailable--etc-kubernetes-manifests-etcd.yaml,Port-10250,Swap,Mem"
I1109 11:03:17.165799 1054993 out.go:203]     ‚ñ™ Generating certificates and keys ...
I1109 11:03:20.817735 1054993 out.go:203]     ‚ñ™ Booting up control plane ...
I1109 11:03:31.425301 1054993 out.go:203]     ‚ñ™ Configuring RBAC rules ...
I1109 11:03:32.185088 1054993 cni.go:93] Creating CNI manager for ""
I1109 11:03:32.185113 1054993 cni.go:147] Driver none used, CNI unnecessary in this configuration, recommending no CNI
I1109 11:03:32.185171 1054993 exec_runner.go:51] Run: /bin/bash -c "cat /proc/$(pgrep kube-apiserver)/oom_adj"
I1109 11:03:32.185451 1054993 exec_runner.go:51] Run: sudo /var/lib/minikube/binaries/v1.22.3/kubectl create clusterrolebinding minikube-rbac --clusterrole=cluster-admin --serviceaccount=kube-system:default --kubeconfig=/var/lib/minikube/kubeconfig
I1109 11:03:32.185573 1054993 exec_runner.go:51] Run: sudo /var/lib/minikube/binaries/v1.22.3/kubectl label nodes minikube.k8s.io/version=v1.24.0 minikube.k8s.io/commit=76b94fb3c4e8ac5062daf70d60cf03ddcc0a741b minikube.k8s.io/name=minikube minikube.k8s.io/updated_at=2021_11_09T11_03_32_0700 --all --overwrite --kubeconfig=/var/lib/minikube/kubeconfig
I1109 11:03:32.241416 1054993 ops.go:34] apiserver oom_adj: -16
I1109 11:03:32.446920 1054993 kubeadm.go:985] duration metric: took 261.558757ms to wait for elevateKubeSystemPrivileges.
I1109 11:03:32.606089 1054993 kubeadm.go:392] StartCluster complete in 16.46813994s
I1109 11:03:32.606125 1054993 settings.go:142] acquiring lock: {Name:mk19004591210340446308469f521c5cfa3e1599 Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
I1109 11:03:32.606227 1054993 settings.go:150] Updating kubeconfig:  /root/.kube/config
I1109 11:03:32.607599 1054993 lock.go:35] WriteFile acquiring /root/.kube/config: {Name:mk72a1487fd2da23da9e8181e16f352a6105bd56 Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
I1109 11:03:33.153090 1054993 kapi.go:244] deployment "coredns" in namespace "kube-system" and context "minikube" rescaled to 1
I1109 11:03:33.153905 1054993 out.go:176] ü§π  Configuring local host environment ...
I1109 11:03:33.153271 1054993 exec_runner.go:51] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.22.3/kubectl --kubeconfig=/var/lib/minikube/kubeconfig -n kube-system get configmap coredns -o yaml"
W1109 11:03:33.154108 1054993 out.go:241] 
W1109 11:03:33.154125 1054993 out.go:241] ‚ùó  The 'none' driver is designed for experts who need to integrate with an existing VM
W1109 11:03:33.154131 1054993 out.go:241] üí°  Most users should use the newer 'docker' driver instead, which does not require root!
W1109 11:03:33.154135 1054993 out.go:241] üìò  For more information, see: https://minikube.sigs.k8s.io/docs/reference/drivers/none/
W1109 11:03:33.154139 1054993 out.go:241] 
W1109 11:03:33.154293 1054993 out.go:241] ‚ùó  kubectl and minikube configuration will be stored in /root
W1109 11:03:33.154301 1054993 out.go:241] ‚ùó  To use kubectl or minikube commands as your own user, you may need to relocate them. For example, to overwrite your own settings, run:
W1109 11:03:33.154306 1054993 out.go:241] 
I1109 11:03:33.153552 1054993 addons.go:415] enableAddons start: toEnable=map[], additional=[]
W1109 11:03:33.154360 1054993 out.go:241]     ‚ñ™ sudo mv /root/.kube /root/.minikube $HOME
W1109 11:03:33.154367 1054993 out.go:241]     ‚ñ™ sudo chown -R $USER $HOME/.kube $HOME/.minikube
W1109 11:03:33.154371 1054993 out.go:241] 
W1109 11:03:33.154374 1054993 out.go:241] üí°  This can also be done automatically by setting the env var CHANGE_MINIKUBE_NONE_USER=true
I1109 11:03:33.154392 1054993 start.go:229] Will wait 6m0s for node &{Name:m01 IP:207.154.254.97 Port:8443 KubernetesVersion:v1.22.3 ControlPlane:true Worker:true}
I1109 11:03:33.154413 1054993 addons.go:65] Setting storage-provisioner=true in profile "minikube"
I1109 11:03:33.155867 1054993 out.go:176] üîé  Verifying Kubernetes components...
I1109 11:03:33.155954 1054993 exec_runner.go:51] Run: sudo systemctl is-active --quiet service kubelet
I1109 11:03:33.154428 1054993 addons.go:153] Setting addon storage-provisioner=true in "minikube"
W1109 11:03:33.156236 1054993 addons.go:165] addon storage-provisioner should already be in state true
I1109 11:03:33.156263 1054993 host.go:66] Checking if "minikube" exists ...
I1109 11:03:33.156857 1054993 kubeconfig.go:92] found "minikube" server: "https://207.154.254.97:8443"
I1109 11:03:33.156867 1054993 api_server.go:165] Checking apiserver status ...
I1109 11:03:33.156888 1054993 exec_runner.go:51] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I1109 11:03:33.153709 1054993 config.go:176] Loaded profile config "minikube": Driver=none, ContainerRuntime=docker, KubernetesVersion=v1.22.3
I1109 11:03:33.154452 1054993 addons.go:65] Setting default-storageclass=true in profile "minikube"
I1109 11:03:33.156957 1054993 addons_storage_classes.go:33] enableOrDisableStorageClasses default-storageclass=true on "minikube"
I1109 11:03:33.157221 1054993 kubeconfig.go:92] found "minikube" server: "https://207.154.254.97:8443"
I1109 11:03:33.157226 1054993 api_server.go:165] Checking apiserver status ...
I1109 11:03:33.157238 1054993 exec_runner.go:51] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I1109 11:03:33.179487 1054993 exec_runner.go:51] Run: sudo egrep ^[0-9]+:freezer: /proc/1056359/cgroup
I1109 11:03:33.180747 1054993 api_server.go:51] waiting for apiserver process to appear ...
I1109 11:03:33.180798 1054993 exec_runner.go:51] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I1109 11:03:33.188328 1054993 exec_runner.go:51] Run: sudo egrep ^[0-9]+:freezer: /proc/1056359/cgroup
I1109 11:03:33.199399 1054993 api_server.go:181] apiserver freezer: "9:freezer:/kubepods/burstable/pod60c00c2045f5585732074dba3a9b01a8/b8b5c787f5f5d2c3ca7e50a69cf6e477f32d4c67752ff46c4254b04369ec6905"
I1109 11:03:33.199461 1054993 exec_runner.go:51] Run: sudo cat /sys/fs/cgroup/freezer/kubepods/burstable/pod60c00c2045f5585732074dba3a9b01a8/b8b5c787f5f5d2c3ca7e50a69cf6e477f32d4c67752ff46c4254b04369ec6905/freezer.state
I1109 11:03:33.202024 1054993 api_server.go:181] apiserver freezer: "9:freezer:/kubepods/burstable/pod60c00c2045f5585732074dba3a9b01a8/b8b5c787f5f5d2c3ca7e50a69cf6e477f32d4c67752ff46c4254b04369ec6905"
I1109 11:03:33.202094 1054993 exec_runner.go:51] Run: sudo cat /sys/fs/cgroup/freezer/kubepods/burstable/pod60c00c2045f5585732074dba3a9b01a8/b8b5c787f5f5d2c3ca7e50a69cf6e477f32d4c67752ff46c4254b04369ec6905/freezer.state
I1109 11:03:33.234023 1054993 api_server.go:203] freezer state: "THAWED"
I1109 11:03:33.234047 1054993 api_server.go:240] Checking apiserver healthz at https://207.154.254.97:8443/healthz ...
I1109 11:03:33.240169 1054993 api_server.go:266] https://207.154.254.97:8443/healthz returned 200:
ok
I1109 11:03:33.244666 1054993 addons.go:153] Setting addon default-storageclass=true in "minikube"
W1109 11:03:33.244678 1054993 addons.go:165] addon default-storageclass should already be in state true
I1109 11:03:33.244702 1054993 host.go:66] Checking if "minikube" exists ...
I1109 11:03:33.245268 1054993 kubeconfig.go:92] found "minikube" server: "https://207.154.254.97:8443"
I1109 11:03:33.245281 1054993 api_server.go:165] Checking apiserver status ...
I1109 11:03:33.245320 1054993 exec_runner.go:51] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I1109 11:03:33.246689 1054993 api_server.go:203] freezer state: "THAWED"
I1109 11:03:33.246707 1054993 api_server.go:240] Checking apiserver healthz at https://207.154.254.97:8443/healthz ...
I1109 11:03:33.255010 1054993 api_server.go:266] https://207.154.254.97:8443/healthz returned 200:
ok
I1109 11:03:33.257387 1054993 out.go:176]     ‚ñ™ Using image gcr.io/k8s-minikube/storage-provisioner:v5
I1109 11:03:33.257513 1054993 addons.go:348] installing /etc/kubernetes/addons/storage-provisioner.yaml
I1109 11:03:33.257526 1054993 exec_runner.go:144] found /etc/kubernetes/addons/storage-provisioner.yaml, removing ...
I1109 11:03:33.257531 1054993 exec_runner.go:207] rm: /etc/kubernetes/addons/storage-provisioner.yaml
I1109 11:03:33.257588 1054993 exec_runner.go:151] cp: memory --> /etc/kubernetes/addons/storage-provisioner.yaml (2676 bytes)
I1109 11:03:33.257701 1054993 exec_runner.go:51] Run: sudo cp -a /tmp/minikube948346583 /etc/kubernetes/addons/storage-provisioner.yaml
I1109 11:03:33.264426 1054993 api_server.go:71] duration metric: took 109.996379ms to wait for apiserver process to appear ...
I1109 11:03:33.264441 1054993 api_server.go:87] waiting for apiserver healthz status ...
I1109 11:03:33.264451 1054993 api_server.go:240] Checking apiserver healthz at https://207.154.254.97:8443/healthz ...
I1109 11:03:33.269415 1054993 api_server.go:266] https://207.154.254.97:8443/healthz returned 200:
ok
I1109 11:03:33.270380 1054993 api_server.go:140] control plane version: v1.22.3
I1109 11:03:33.270393 1054993 api_server.go:130] duration metric: took 5.947218ms to wait for apiserver health ...
I1109 11:03:33.270399 1054993 system_pods.go:43] waiting for kube-system pods to appear ...
I1109 11:03:33.307157 1054993 exec_runner.go:51] Run: sudo egrep ^[0-9]+:freezer: /proc/1056359/cgroup
I1109 11:03:33.308693 1054993 system_pods.go:59] 4 kube-system pods found
I1109 11:03:33.308709 1054993 system_pods.go:61] "etcd-ubuntu-s-2vcpu-4gb-intel-fra1-01" [1b50d05d-abb8-48d0-a5cc-092da343a4b6] Pending
I1109 11:03:33.308719 1054993 system_pods.go:61] "kube-apiserver-ubuntu-s-2vcpu-4gb-intel-fra1-01" [2fa61be4-77d8-45ec-90af-b52380e42606] Running / Ready:ContainersNotReady (containers with unready status: [kube-apiserver]) / ContainersReady:ContainersNotReady (containers with unready status: [kube-apiserver])
I1109 11:03:33.308725 1054993 system_pods.go:61] "kube-controller-manager-ubuntu-s-2vcpu-4gb-intel-fra1-01" [a25d4ac3-a406-4b41-85c5-ebc6a8b71283] Pending
I1109 11:03:33.308729 1054993 system_pods.go:61] "kube-scheduler-ubuntu-s-2vcpu-4gb-intel-fra1-01" [c91af0f8-2668-439e-a8cd-0337444cd675] Pending
I1109 11:03:33.308735 1054993 system_pods.go:74] duration metric: took 38.330616ms to wait for pod list to return data ...
I1109 11:03:33.308742 1054993 kubeadm.go:547] duration metric: took 154.319983ms to wait for : map[apiserver:true system_pods:true] ...
I1109 11:03:33.308753 1054993 node_conditions.go:102] verifying NodePressure condition ...
I1109 11:03:33.313503 1054993 node_conditions.go:122] node storage ephemeral capacity is 81120644Ki
I1109 11:03:33.314378 1054993 node_conditions.go:123] node cpu capacity is 2
I1109 11:03:33.314399 1054993 node_conditions.go:105] duration metric: took 5.640297ms to run NodePressure ...
I1109 11:03:33.314412 1054993 start.go:234] waiting for startup goroutines ...
I1109 11:03:33.323906 1054993 api_server.go:181] apiserver freezer: "9:freezer:/kubepods/burstable/pod60c00c2045f5585732074dba3a9b01a8/b8b5c787f5f5d2c3ca7e50a69cf6e477f32d4c67752ff46c4254b04369ec6905"
I1109 11:03:33.323956 1054993 exec_runner.go:51] Run: sudo cat /sys/fs/cgroup/freezer/kubepods/burstable/pod60c00c2045f5585732074dba3a9b01a8/b8b5c787f5f5d2c3ca7e50a69cf6e477f32d4c67752ff46c4254b04369ec6905/freezer.state
I1109 11:03:33.324139 1054993 exec_runner.go:51] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.22.3/kubectl apply -f /etc/kubernetes/addons/storage-provisioner.yaml
I1109 11:03:33.350762 1054993 api_server.go:203] freezer state: "THAWED"
I1109 11:03:33.350783 1054993 api_server.go:240] Checking apiserver healthz at https://207.154.254.97:8443/healthz ...
I1109 11:03:33.355920 1054993 api_server.go:266] https://207.154.254.97:8443/healthz returned 200:
ok
I1109 11:03:33.356020 1054993 addons.go:348] installing /etc/kubernetes/addons/storageclass.yaml
I1109 11:03:33.356047 1054993 exec_runner.go:144] found /etc/kubernetes/addons/storageclass.yaml, removing ...
I1109 11:03:33.356056 1054993 exec_runner.go:207] rm: /etc/kubernetes/addons/storageclass.yaml
I1109 11:03:33.356130 1054993 exec_runner.go:151] cp: memory --> /etc/kubernetes/addons/storageclass.yaml (271 bytes)
I1109 11:03:33.356263 1054993 exec_runner.go:51] Run: sudo cp -a /tmp/minikube2169550903 /etc/kubernetes/addons/storageclass.yaml
I1109 11:03:33.360717 1054993 exec_runner.go:51] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.22.3/kubectl --kubeconfig=/var/lib/minikube/kubeconfig -n kube-system get configmap coredns -o yaml | sed '/^        forward . \/etc\/resolv.conf.*/i \        hosts {\n           127.0.0.1 host.minikube.internal\n           fallthrough\n        }' | sudo /var/lib/minikube/binaries/v1.22.3/kubectl --kubeconfig=/var/lib/minikube/kubeconfig replace -f -"
I1109 11:03:33.388263 1054993 exec_runner.go:51] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.22.3/kubectl apply -f /etc/kubernetes/addons/storageclass.yaml
I1109 11:03:33.791290 1054993 out.go:176] üåü  Enabled addons: storage-provisioner, default-storageclass
I1109 11:03:33.791483 1054993 addons.go:417] enableAddons completed in 637.927018ms
I1109 11:03:33.824937 1054993 start.go:739] {"host.minikube.internal": 127.0.0.1} host record injected into CoreDNS
I1109 11:03:33.857688 1054993 start.go:473] kubectl: 1.22.3, cluster: 1.22.3 (minor skew: 0)
I1109 11:03:33.858556 1054993 out.go:176] üèÑ  Done! kubectl is now configured to use "minikube" cluster and "default" namespace by default

* 
* ==> Docker <==
* -- Logs begin at Sat 2021-11-06 11:33:41 UTC, end at Tue 2021-11-09 11:12:08 UTC. --
Nov 09 09:36:07 ubuntu-s-2vcpu-4gb-intel-fra1-01 dockerd[831820]: time="2021-11-09T09:36:07.468570906Z" level=info msg="ignoring event" container=2c04207060d6acebc2be6b9963c42b641f0070b069479bef77bf8e4191e715e7 module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Nov 09 09:36:13 ubuntu-s-2vcpu-4gb-intel-fra1-01 dockerd[831820]: time="2021-11-09T09:36:13.628331774Z" level=info msg="ignoring event" container=89aeb9d4042c15df184e0d360df6fab0973f9bfe867212caeb62be94cf4cfa24 module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Nov 09 09:36:13 ubuntu-s-2vcpu-4gb-intel-fra1-01 dockerd[831820]: time="2021-11-09T09:36:13.855274242Z" level=info msg="ignoring event" container=26877849279f64c90a1e2affe9a9583cb43ecb39a52b3b4f6f2c34b80d956e23 module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Nov 09 09:36:14 ubuntu-s-2vcpu-4gb-intel-fra1-01 dockerd[831820]: time="2021-11-09T09:36:14.267746304Z" level=info msg="ignoring event" container=e98aff41768a3a3e3b1e63c955c4ea0f9666002852a79d8af39d84f3f96513f6 module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Nov 09 09:36:14 ubuntu-s-2vcpu-4gb-intel-fra1-01 dockerd[831820]: time="2021-11-09T09:36:14.551769762Z" level=info msg="ignoring event" container=ac3ef582bd929633b782573593ac86c991c200e77b1a74cf09f1215e2f922019 module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Nov 09 09:36:14 ubuntu-s-2vcpu-4gb-intel-fra1-01 dockerd[831820]: time="2021-11-09T09:36:14.807485049Z" level=info msg="ignoring event" container=babcba66b9680e06485d5859a68b35923abdec5a836e55626af437adffbfeb42 module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Nov 09 09:36:15 ubuntu-s-2vcpu-4gb-intel-fra1-01 dockerd[831820]: time="2021-11-09T09:36:15.079970767Z" level=info msg="ignoring event" container=7ac9967ac680f26669df08835516393eadb90a0b242e2d1aecbab4b9513ef94d module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Nov 09 09:36:25 ubuntu-s-2vcpu-4gb-intel-fra1-01 dockerd[831820]: time="2021-11-09T09:36:25.290130887Z" level=info msg="Container failed to exit within 10s of signal 15 - using the force" container=05c370a89cf546d03e09eb93ed78d631923cc06f2208ed17bbddaf52a6b336b1
Nov 09 09:36:25 ubuntu-s-2vcpu-4gb-intel-fra1-01 dockerd[831820]: time="2021-11-09T09:36:25.363391162Z" level=info msg="ignoring event" container=05c370a89cf546d03e09eb93ed78d631923cc06f2208ed17bbddaf52a6b336b1 module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Nov 09 09:36:25 ubuntu-s-2vcpu-4gb-intel-fra1-01 dockerd[831820]: time="2021-11-09T09:36:25.558557151Z" level=info msg="ignoring event" container=3e7d0264f7f04d705cdd78b74d89590ffa623bfffac07116d1da7bd7144db392 module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Nov 09 09:36:25 ubuntu-s-2vcpu-4gb-intel-fra1-01 dockerd[831820]: time="2021-11-09T09:36:25.745461965Z" level=info msg="ignoring event" container=73c25f747970532fe3112b29a6319687cd4e46e15247e3e33fc094c67d64d985 module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Nov 09 09:36:35 ubuntu-s-2vcpu-4gb-intel-fra1-01 dockerd[831820]: time="2021-11-09T09:36:35.895253900Z" level=info msg="Container failed to exit within 10s of signal 15 - using the force" container=756696f27c6cdac34479483da6a2ee7a622d76459e2934bdbfc9a35de75bee9d
Nov 09 09:36:35 ubuntu-s-2vcpu-4gb-intel-fra1-01 dockerd[831820]: time="2021-11-09T09:36:35.958885343Z" level=info msg="ignoring event" container=756696f27c6cdac34479483da6a2ee7a622d76459e2934bdbfc9a35de75bee9d module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Nov 09 09:36:36 ubuntu-s-2vcpu-4gb-intel-fra1-01 dockerd[831820]: time="2021-11-09T09:36:36.146794414Z" level=info msg="ignoring event" container=73508b393c65ee54d7d12c3429ccc05b267c802998bb4b43f2b872f98039ead1 module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Nov 09 09:36:36 ubuntu-s-2vcpu-4gb-intel-fra1-01 dockerd[831820]: time="2021-11-09T09:36:36.343525947Z" level=info msg="ignoring event" container=9c79bcffe850a782fac2dbb05aae0a5a01bcdcee6863cbc3a8a2f420d50c5ac8 module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Nov 09 09:36:36 ubuntu-s-2vcpu-4gb-intel-fra1-01 dockerd[831820]: time="2021-11-09T09:36:36.511025220Z" level=info msg="ignoring event" container=67b79d9649316ebe5e72cb53b7a3d2c6f42a2380f23b6d0cec4440e24914f3e3 module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Nov 09 09:36:36 ubuntu-s-2vcpu-4gb-intel-fra1-01 dockerd[831820]: time="2021-11-09T09:36:36.683438889Z" level=info msg="ignoring event" container=eee23e645d6e85714de7f301ab9c38a9c89d5ce5cc9937fa50851c7687ebe607 module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Nov 09 09:36:57 ubuntu-s-2vcpu-4gb-intel-fra1-01 dockerd[831820]: time="2021-11-09T09:36:57.413989775Z" level=info msg="ignoring event" container=5a4929bdf2f26c53fb3f2498e05b3eb59bbb0ea708fb744e20b4898c034d86aa module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Nov 09 09:36:58 ubuntu-s-2vcpu-4gb-intel-fra1-01 dockerd[831820]: time="2021-11-09T09:36:58.087356592Z" level=info msg="No non-localhost DNS nameservers are left in resolv.conf. Using default external servers: [nameserver 8.8.8.8 nameserver 8.8.4.4]"
Nov 09 09:36:58 ubuntu-s-2vcpu-4gb-intel-fra1-01 dockerd[831820]: time="2021-11-09T09:36:58.087407584Z" level=info msg="IPv6 enabled; Adding default IPv6 external servers: [nameserver 2001:4860:4860::8888 nameserver 2001:4860:4860::8844]"
Nov 09 09:36:58 ubuntu-s-2vcpu-4gb-intel-fra1-01 dockerd[831820]: time="2021-11-09T09:36:58.379818845Z" level=warning msg="path in container /dev/fuse already exists in privileged mode" container=197526c47847db5df6ce123ace9fe0a973ce9f436a29d24d252ab09e011b8816
Nov 09 09:37:06 ubuntu-s-2vcpu-4gb-intel-fra1-01 dockerd[831820]: time="2021-11-09T09:37:06.761571099Z" level=info msg="ignoring event" container=52dfb57d315accc838163d61d3bf2e2398364c5157bd1eef3a8ede7720097e78 module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Nov 09 11:02:56 ubuntu-s-2vcpu-4gb-intel-fra1-01 dockerd[831820]: time="2021-11-09T11:02:56.039851422Z" level=info msg="ignoring event" container=197526c47847db5df6ce123ace9fe0a973ce9f436a29d24d252ab09e011b8816 module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Nov 09 11:03:13 ubuntu-s-2vcpu-4gb-intel-fra1-01 systemd[1]: Stopping Docker Application Container Engine...
Nov 09 11:03:13 ubuntu-s-2vcpu-4gb-intel-fra1-01 dockerd[831820]: time="2021-11-09T11:03:13.135250501Z" level=info msg="Processing signal 'terminated'"
Nov 09 11:03:13 ubuntu-s-2vcpu-4gb-intel-fra1-01 dockerd[831820]: time="2021-11-09T11:03:13.152042321Z" level=info msg="stopping event stream following graceful shutdown" error="<nil>" module=libcontainerd namespace=moby
Nov 09 11:03:13 ubuntu-s-2vcpu-4gb-intel-fra1-01 dockerd[831820]: time="2021-11-09T11:03:13.152562416Z" level=info msg="Daemon shutdown complete"
Nov 09 11:03:13 ubuntu-s-2vcpu-4gb-intel-fra1-01 systemd[1]: docker.service: Succeeded.
Nov 09 11:03:13 ubuntu-s-2vcpu-4gb-intel-fra1-01 systemd[1]: Stopped Docker Application Container Engine.
Nov 09 11:03:13 ubuntu-s-2vcpu-4gb-intel-fra1-01 systemd[1]: Starting Docker Application Container Engine...
Nov 09 11:03:13 ubuntu-s-2vcpu-4gb-intel-fra1-01 dockerd[1055121]: time="2021-11-09T11:03:13.290914320Z" level=info msg="Starting up"
Nov 09 11:03:13 ubuntu-s-2vcpu-4gb-intel-fra1-01 dockerd[1055121]: time="2021-11-09T11:03:13.293535043Z" level=info msg="detected 127.0.0.53 nameserver, assuming systemd-resolved, so using resolv.conf: /run/systemd/resolve/resolv.conf"
Nov 09 11:03:13 ubuntu-s-2vcpu-4gb-intel-fra1-01 dockerd[1055121]: time="2021-11-09T11:03:13.296699115Z" level=info msg="parsed scheme: \"unix\"" module=grpc
Nov 09 11:03:13 ubuntu-s-2vcpu-4gb-intel-fra1-01 dockerd[1055121]: time="2021-11-09T11:03:13.296914917Z" level=info msg="scheme \"unix\" not registered, fallback to default scheme" module=grpc
Nov 09 11:03:13 ubuntu-s-2vcpu-4gb-intel-fra1-01 dockerd[1055121]: time="2021-11-09T11:03:13.297016944Z" level=info msg="ccResolverWrapper: sending update to cc: {[{unix:///run/containerd/containerd.sock  <nil> 0 <nil>}] <nil> <nil>}" module=grpc
Nov 09 11:03:13 ubuntu-s-2vcpu-4gb-intel-fra1-01 dockerd[1055121]: time="2021-11-09T11:03:13.297117162Z" level=info msg="ClientConn switching balancer to \"pick_first\"" module=grpc
Nov 09 11:03:13 ubuntu-s-2vcpu-4gb-intel-fra1-01 dockerd[1055121]: time="2021-11-09T11:03:13.302846858Z" level=info msg="parsed scheme: \"unix\"" module=grpc
Nov 09 11:03:13 ubuntu-s-2vcpu-4gb-intel-fra1-01 dockerd[1055121]: time="2021-11-09T11:03:13.302905839Z" level=info msg="scheme \"unix\" not registered, fallback to default scheme" module=grpc
Nov 09 11:03:13 ubuntu-s-2vcpu-4gb-intel-fra1-01 dockerd[1055121]: time="2021-11-09T11:03:13.302930498Z" level=info msg="ccResolverWrapper: sending update to cc: {[{unix:///run/containerd/containerd.sock  <nil> 0 <nil>}] <nil> <nil>}" module=grpc
Nov 09 11:03:13 ubuntu-s-2vcpu-4gb-intel-fra1-01 dockerd[1055121]: time="2021-11-09T11:03:13.302945082Z" level=info msg="ClientConn switching balancer to \"pick_first\"" module=grpc
Nov 09 11:03:13 ubuntu-s-2vcpu-4gb-intel-fra1-01 dockerd[1055121]: time="2021-11-09T11:03:13.403336459Z" level=info msg="[graphdriver] using prior storage driver: overlay2"
Nov 09 11:03:13 ubuntu-s-2vcpu-4gb-intel-fra1-01 dockerd[1055121]: time="2021-11-09T11:03:13.497492040Z" level=warning msg="Your kernel does not support swap memory limit"
Nov 09 11:03:13 ubuntu-s-2vcpu-4gb-intel-fra1-01 dockerd[1055121]: time="2021-11-09T11:03:13.497702269Z" level=warning msg="Your kernel does not support CPU realtime scheduler"
Nov 09 11:03:13 ubuntu-s-2vcpu-4gb-intel-fra1-01 dockerd[1055121]: time="2021-11-09T11:03:13.497788918Z" level=warning msg="Your kernel does not support cgroup blkio weight"
Nov 09 11:03:13 ubuntu-s-2vcpu-4gb-intel-fra1-01 dockerd[1055121]: time="2021-11-09T11:03:13.497846298Z" level=warning msg="Your kernel does not support cgroup blkio weight_device"
Nov 09 11:03:13 ubuntu-s-2vcpu-4gb-intel-fra1-01 dockerd[1055121]: time="2021-11-09T11:03:13.498568916Z" level=info msg="Loading containers: start."
Nov 09 11:03:13 ubuntu-s-2vcpu-4gb-intel-fra1-01 dockerd[1055121]: time="2021-11-09T11:03:13.627647692Z" level=info msg="Default bridge (docker0) is assigned with an IP address 172.17.0.0/16. Daemon option --bip can be used to set a preferred IP address"
Nov 09 11:03:13 ubuntu-s-2vcpu-4gb-intel-fra1-01 dockerd[1055121]: time="2021-11-09T11:03:13.666137690Z" level=info msg="Loading containers: done."
Nov 09 11:03:13 ubuntu-s-2vcpu-4gb-intel-fra1-01 dockerd[1055121]: time="2021-11-09T11:03:13.685506393Z" level=info msg="Docker daemon" commit=e2f740d graphdriver(s)=overlay2 version=20.10.10
Nov 09 11:03:13 ubuntu-s-2vcpu-4gb-intel-fra1-01 dockerd[1055121]: time="2021-11-09T11:03:13.685579869Z" level=info msg="Daemon has completed initialization"
Nov 09 11:03:13 ubuntu-s-2vcpu-4gb-intel-fra1-01 systemd[1]: Started Docker Application Container Engine.
Nov 09 11:03:13 ubuntu-s-2vcpu-4gb-intel-fra1-01 dockerd[1055121]: time="2021-11-09T11:03:13.725528670Z" level=info msg="API listen on /run/docker.sock"
Nov 09 11:03:46 ubuntu-s-2vcpu-4gb-intel-fra1-01 dockerd[1055121]: time="2021-11-09T11:03:46.035060632Z" level=warning msg="Your kernel does not support swap limit capabilities or the cgroup is not mounted. Memory limited without swap."
Nov 09 11:03:54 ubuntu-s-2vcpu-4gb-intel-fra1-01 dockerd[1055121]: time="2021-11-09T11:03:54.708497405Z" level=info msg="ignoring event" container=4dad0936b856ab34fd3d353c914e7fa6b38fcadbb398b73d4b075d5e1c15e9a2 module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Nov 09 11:03:54 ubuntu-s-2vcpu-4gb-intel-fra1-01 dockerd[1055121]: time="2021-11-09T11:03:54.712117084Z" level=info msg="ignoring event" container=e2820aaf507b5ce76b6285fec8955de272f5229d90c1af972685f10c9cd258cf module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Nov 09 11:03:55 ubuntu-s-2vcpu-4gb-intel-fra1-01 dockerd[1055121]: time="2021-11-09T11:03:55.602756540Z" level=info msg="ignoring event" container=cd68115283791a1b45db40e3d082ae9a54be36816692059f547480f3b06e6ec9 module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Nov 09 11:03:55 ubuntu-s-2vcpu-4gb-intel-fra1-01 dockerd[1055121]: time="2021-11-09T11:03:55.903267711Z" level=info msg="ignoring event" container=71b9f9b5a752e555dc8baf510ed50c0a60fe39c2efccd00c3e858c459945e62f module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Nov 09 11:03:56 ubuntu-s-2vcpu-4gb-intel-fra1-01 dockerd[1055121]: time="2021-11-09T11:03:56.605224872Z" level=info msg="ignoring event" container=5deccb64d09a5b0eb1c6edec303512a723528c97d5143b44073cc90b3cb8818c module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Nov 09 11:08:47 ubuntu-s-2vcpu-4gb-intel-fra1-01 dockerd[1055121]: time="2021-11-09T11:08:47.409028339Z" level=info msg="ignoring event" container=bb18deef804c293f35d6346ec1f36e0adadc679108eb14ee3cf1fbb88330d2a4 module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Nov 09 11:08:47 ubuntu-s-2vcpu-4gb-intel-fra1-01 dockerd[1055121]: time="2021-11-09T11:08:47.488490829Z" level=info msg="ignoring event" container=cf978a5a1bc214f0923e3ec39fdd0e5bb9537e216d836aaeda92dccf4bced065 module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"

* 
* ==> container status <==
* sudo: crictl: command not found
CONTAINER ID   IMAGE                   COMMAND                  CREATED         STATUS                     PORTS                                                                      NAMES
191e019864e0   a9f76bcccfb5            "/usr/bin/dumb-init ‚Ä¶"   3 minutes ago   Up 3 minutes                                                                                          k8s_controller_ingress-nginx-controller-5f66978484-w8qm7_ingress-nginx_ce45aee3-c47d-45b1-bbc2-d7575b1c100f_0
1de09b1aef47   k8s.gcr.io/pause:3.5    "/pause"                 3 minutes ago   Up 3 minutes               0.0.0.0:80->80/tcp, :::80->80/tcp, 0.0.0.0:443->443/tcp, :::443->443/tcp   k8s_POD_ingress-nginx-controller-5f66978484-w8qm7_ingress-nginx_ce45aee3-c47d-45b1-bbc2-d7575b1c100f_0
d3e4627aa478   7801cfc6d5c0            "/metrics-sidecar"       4 minutes ago   Up 4 minutes                                                                                          k8s_dashboard-metrics-scraper_dashboard-metrics-scraper-5594458c94-5d9kh_kubernetes-dashboard_b83cab05-ba47-4667-ba8c-0469b4c69b87_0
1b276a76bb2c   e1482a24335a            "/dashboard --insecu‚Ä¶"   4 minutes ago   Up 4 minutes                                                                                          k8s_kubernetes-dashboard_kubernetes-dashboard-654cf69797-n4d2t_kubernetes-dashboard_aee4b048-badc-47a6-848a-1d0f1f284aa0_0
29a73c73698a   k8s.gcr.io/pause:3.5    "/pause"                 4 minutes ago   Up 4 minutes                                                                                          k8s_POD_kubernetes-dashboard-654cf69797-n4d2t_kubernetes-dashboard_aee4b048-badc-47a6-848a-1d0f1f284aa0_0
2fd6ea861bf4   k8s.gcr.io/pause:3.5    "/pause"                 4 minutes ago   Up 4 minutes                                                                                          k8s_POD_dashboard-metrics-scraper-5594458c94-5d9kh_kubernetes-dashboard_b83cab05-ba47-4667-ba8c-0469b4c69b87_0
ab959b360c0f   abed47/mawahib-query    "docker-entrypoint.s‚Ä¶"   6 minutes ago   Up 6 minutes                                                                                          k8s_mawahib-query_query-depl-d6f444ffd-8lvc2_default_1c32a68d-660f-4ec9-9965-76d834fdf38a_0
62924fc037e6   k8s.gcr.io/pause:3.5    "/pause"                 6 minutes ago   Up 6 minutes                                                                                          k8s_POD_query-depl-d6f444ffd-8lvc2_default_1c32a68d-660f-4ec9-9965-76d834fdf38a_0
3db3cbf7ca95   abed47/mawahib-videos   "docker-entrypoint.s‚Ä¶"   7 minutes ago   Up 7 minutes                                                                                          k8s_mawahib-videos_videos-depl-569b4b45bd-k46sh_default_c546c002-091a-4b24-b347-f3583c1cd01d_0
ae7e5b15112b   k8s.gcr.io/pause:3.5    "/pause"                 7 minutes ago   Up 7 minutes                                                                                          k8s_POD_videos-depl-569b4b45bd-k46sh_default_c546c002-091a-4b24-b347-f3583c1cd01d_0
a7f1246d1720   abed47/mawahib-users    "docker-entrypoint.s‚Ä¶"   7 minutes ago   Up 7 minutes                                                                                          k8s_mawahib-users_users-depl-7cdfd8447d-45zvh_default_71941977-4952-42fd-99ec-24a0ba4e315e_0
b4d47684c20d   k8s.gcr.io/pause:3.5    "/pause"                 7 minutes ago   Up 7 minutes                                                                                          k8s_POD_users-depl-7cdfd8447d-45zvh_default_71941977-4952-42fd-99ec-24a0ba4e315e_0
2fdac1be0ff1   411737a82b95            "/nats-streaming-ser‚Ä¶"   7 minutes ago   Up 7 minutes                                                                                          k8s_nats_nats-depl-6bd8d44b6f-w5p4w_default_64060ebb-ec0e-4116-bc18-5f25fe5aaeeb_0
8f5819261b6c   k8s.gcr.io/pause:3.5    "/pause"                 7 minutes ago   Up 7 minutes                                                                                          k8s_POD_nats-depl-6bd8d44b6f-w5p4w_default_64060ebb-ec0e-4116-bc18-5f25fe5aaeeb_0
71b9f9b5a752   c41e9fcadf5a            "/kube-webhook-certg‚Ä¶"   8 minutes ago   Exited (0) 8 minutes ago                                                                              k8s_patch_ingress-nginx-admission-patch--1-4hjr9_ingress-nginx_9a255ef3-80e7-4a14-ac79-3d114811dd5d_1
4dad0936b856   c41e9fcadf5a            "/kube-webhook-certg‚Ä¶"   8 minutes ago   Exited (0) 8 minutes ago                                                                              k8s_create_ingress-nginx-admission-create--1-m9skj_ingress-nginx_f1393e61-6468-46b8-92ab-2c5bbcc60a3b_0
cd6811528379   k8s.gcr.io/pause:3.5    "/pause"                 8 minutes ago   Exited (0) 8 minutes ago                                                                              k8s_POD_ingress-nginx-admission-create--1-m9skj_ingress-nginx_f1393e61-6468-46b8-92ab-2c5bbcc60a3b_0
5deccb64d09a   k8s.gcr.io/pause:3.5    "/pause"                 8 minutes ago   Exited (0) 8 minutes ago                                                                              k8s_POD_ingress-nginx-admission-patch--1-4hjr9_ingress-nginx_9a255ef3-80e7-4a14-ac79-3d114811dd5d_0
5e56b5a424e8   8d147537fb7d            "/coredns -conf /etc‚Ä¶"   8 minutes ago   Up 8 minutes                                                                                          k8s_coredns_coredns-78fcd69978-6ssh6_kube-system_ef28b435-77ea-4e7a-80fb-432950f9f355_0
41313c7f0c94   6e38f40d628d            "/storage-provisioner"   8 minutes ago   Up 8 minutes                                                                                          k8s_storage-provisioner_storage-provisioner_kube-system_0fb869f3-a26a-4f3d-98b3-788fcc6b64e9_0
d0687a873fdb   k8s.gcr.io/pause:3.5    "/pause"                 8 minutes ago   Up 8 minutes                                                                                          k8s_POD_storage-provisioner_kube-system_0fb869f3-a26a-4f3d-98b3-788fcc6b64e9_0
83b4b51dcb97   6120bd723dce            "/usr/local/bin/kube‚Ä¶"   8 minutes ago   Up 8 minutes                                                                                          k8s_kube-proxy_kube-proxy-dddlp_kube-system_b6ae86fd-488b-4e11-b051-2e4b274ff5ec_0
b814d759c06d   k8s.gcr.io/pause:3.5    "/pause"                 8 minutes ago   Up 8 minutes                                                                                          k8s_POD_kube-proxy-dddlp_kube-system_b6ae86fd-488b-4e11-b051-2e4b274ff5ec_0
815261ced11c   k8s.gcr.io/pause:3.5    "/pause"                 8 minutes ago   Up 8 minutes                                                                                          k8s_POD_coredns-78fcd69978-6ssh6_kube-system_ef28b435-77ea-4e7a-80fb-432950f9f355_0
b8b5c787f5f5   53224b502ea4            "kube-apiserver --ad‚Ä¶"   8 minutes ago   Up 8 minutes                                                                                          k8s_kube-apiserver_kube-apiserver-ubuntu-s-2vcpu-4gb-intel-fra1-01_kube-system_60c00c2045f5585732074dba3a9b01a8_4
9a2d7e6450d1   0aa9c7e31d30            "kube-scheduler --au‚Ä¶"   8 minutes ago   Up 8 minutes                                                                                          k8s_kube-scheduler_kube-scheduler-ubuntu-s-2vcpu-4gb-intel-fra1-01_kube-system_632d62e207d7dcde83d080b09173bd19_4
e821939e19ec   004811815584            "etcd --advertise-cl‚Ä¶"   8 minutes ago   Up 8 minutes                                                                                          k8s_etcd_etcd-ubuntu-s-2vcpu-4gb-intel-fra1-01_kube-system_295146c6a2f816022710c229d15de75c_4
46d692f7c28e   05c905cef780            "kube-controller-man‚Ä¶"   8 minutes ago   Up 8 minutes                                                                                          k8s_kube-controller-manager_kube-controller-manager-ubuntu-s-2vcpu-4gb-intel-fra1-01_kube-system_0b97b90901ef96cc799fd0c4cfbc54c8_4
8f48fab994d5   k8s.gcr.io/pause:3.5    "/pause"                 8 minutes ago   Up 8 minutes                                                                                          k8s_POD_kube-apiserver-ubuntu-s-2vcpu-4gb-intel-fra1-01_kube-system_60c00c2045f5585732074dba3a9b01a8_0
4293dc784bc1   k8s.gcr.io/pause:3.5    "/pause"                 8 minutes ago   Up 8 minutes                                                                                          k8s_POD_etcd-ubuntu-s-2vcpu-4gb-intel-fra1-01_kube-system_295146c6a2f816022710c229d15de75c_0
2cfa319036e3   k8s.gcr.io/pause:3.5    "/pause"                 8 minutes ago   Up 8 minutes                                                                                          k8s_POD_kube-scheduler-ubuntu-s-2vcpu-4gb-intel-fra1-01_kube-system_632d62e207d7dcde83d080b09173bd19_0
0594acdfa167   k8s.gcr.io/pause:3.5    "/pause"                 8 minutes ago   Up 8 minutes                                                                                          k8s_POD_kube-controller-manager-ubuntu-s-2vcpu-4gb-intel-fra1-01_kube-system_0b97b90901ef96cc799fd0c4cfbc54c8_0
3da3429e863f   77c5676c0b49            "/bin/sh -c tsc"         20 hours ago    Exited (1) 20 hours ago                                                                               compassionate_mcnulty

* 
* ==> coredns [5e56b5a424e8] <==
* .:53
[INFO] plugin/reload: Running configuration MD5 = 18bc9b0eddacfe7401a5dfa71defe13e
CoreDNS-1.8.4
linux/amd64, go1.16.4, 053c4d5

* 
* ==> describe nodes <==
* Name:               ubuntu-s-2vcpu-4gb-intel-fra1-01
Roles:              control-plane,master
Labels:             beta.kubernetes.io/arch=amd64
                    beta.kubernetes.io/os=linux
                    kubernetes.io/arch=amd64
                    kubernetes.io/hostname=ubuntu-s-2vcpu-4gb-intel-fra1-01
                    kubernetes.io/os=linux
                    minikube.k8s.io/commit=76b94fb3c4e8ac5062daf70d60cf03ddcc0a741b
                    minikube.k8s.io/name=minikube
                    minikube.k8s.io/updated_at=2021_11_09T11_03_32_0700
                    minikube.k8s.io/version=v1.24.0
                    node-role.kubernetes.io/control-plane=
                    node-role.kubernetes.io/master=
                    node.kubernetes.io/exclude-from-external-load-balancers=
Annotations:        kubeadm.alpha.kubernetes.io/cri-socket: /var/run/dockershim.sock
                    node.alpha.kubernetes.io/ttl: 0
                    volumes.kubernetes.io/controller-managed-attach-detach: true
CreationTimestamp:  Tue, 09 Nov 2021 11:03:28 +0000
Taints:             <none>
Unschedulable:      false
Lease:
  HolderIdentity:  ubuntu-s-2vcpu-4gb-intel-fra1-01
  AcquireTime:     <unset>
  RenewTime:       Tue, 09 Nov 2021 11:12:03 +0000
Conditions:
  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message
  ----             ------  -----------------                 ------------------                ------                       -------
  MemoryPressure   False   Tue, 09 Nov 2021 11:08:44 +0000   Tue, 09 Nov 2021 11:03:24 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available
  DiskPressure     False   Tue, 09 Nov 2021 11:08:44 +0000   Tue, 09 Nov 2021 11:03:24 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure
  PIDPressure      False   Tue, 09 Nov 2021 11:08:44 +0000   Tue, 09 Nov 2021 11:03:24 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available
  Ready            True    Tue, 09 Nov 2021 11:08:44 +0000   Tue, 09 Nov 2021 11:03:43 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled
Addresses:
  InternalIP:  207.154.254.97
  Hostname:    ubuntu-s-2vcpu-4gb-intel-fra1-01
Capacity:
  cpu:                2
  ephemeral-storage:  81120644Ki
  hugepages-1Gi:      0
  hugepages-2Mi:      0
  memory:             4030660Ki
  pods:               110
Allocatable:
  cpu:                2
  ephemeral-storage:  81120644Ki
  hugepages-1Gi:      0
  hugepages-2Mi:      0
  memory:             4030660Ki
  pods:               110
System Info:
  Machine ID:                 8173f7e26bcc45dba85e6d87c4576d14
  System UUID:                8173f7e2-6bcc-45db-a85e-6d87c4576d14
  Boot ID:                    b1a59aaf-5535-48ef-890b-e239030e450a
  Kernel Version:             5.4.0-88-generic
  OS Image:                   Ubuntu 20.04.3 LTS
  Operating System:           linux
  Architecture:               amd64
  Container Runtime Version:  docker://20.10.10
  Kubelet Version:            v1.22.3
  Kube-Proxy Version:         v1.22.3
PodCIDR:                      10.244.0.0/24
PodCIDRs:                     10.244.0.0/24
Non-terminated Pods:          (14 in total)
  Namespace                   Name                                                        CPU Requests  CPU Limits  Memory Requests  Memory Limits  Age
  ---------                   ----                                                        ------------  ----------  ---------------  -------------  ---
  default                     nats-depl-6bd8d44b6f-w5p4w                                  0 (0%!)(MISSING)        0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         7m20s
  default                     query-depl-d6f444ffd-8lvc2                                  0 (0%!)(MISSING)        0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         6m53s
  default                     users-depl-7cdfd8447d-45zvh                                 0 (0%!)(MISSING)        0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         7m14s
  default                     videos-depl-569b4b45bd-k46sh                                0 (0%!)(MISSING)        0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         7m5s
  ingress-nginx               ingress-nginx-controller-5f66978484-w8qm7                   100m (5%!)(MISSING)     0 (0%!)(MISSING)      90Mi (2%!)(MISSING)        0 (0%!)(MISSING)         3m52s
  kube-system                 coredns-78fcd69978-6ssh6                                    100m (5%!)(MISSING)     0 (0%!)(MISSING)      70Mi (1%!)(MISSING)        170Mi (4%!)(MISSING)     8m24s
  kube-system                 etcd-ubuntu-s-2vcpu-4gb-intel-fra1-01                       100m (5%!)(MISSING)     0 (0%!)(MISSING)      100Mi (2%!)(MISSING)       0 (0%!)(MISSING)         8m35s
  kube-system                 kube-apiserver-ubuntu-s-2vcpu-4gb-intel-fra1-01             250m (12%!)(MISSING)    0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         8m38s
  kube-system                 kube-controller-manager-ubuntu-s-2vcpu-4gb-intel-fra1-01    200m (10%!)(MISSING)    0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         8m35s
  kube-system                 kube-proxy-dddlp                                            0 (0%!)(MISSING)        0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         8m25s
  kube-system                 kube-scheduler-ubuntu-s-2vcpu-4gb-intel-fra1-01             100m (5%!)(MISSING)     0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         8m35s
  kube-system                 storage-provisioner                                         0 (0%!)(MISSING)        0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         8m35s
  kubernetes-dashboard        dashboard-metrics-scraper-5594458c94-5d9kh                  0 (0%!)(MISSING)        0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         4m28s
  kubernetes-dashboard        kubernetes-dashboard-654cf69797-n4d2t                       0 (0%!)(MISSING)        0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         4m28s
Allocated resources:
  (Total limits may be over 100 percent, i.e., overcommitted.)
  Resource           Requests    Limits
  --------           --------    ------
  cpu                850m (42%!)(MISSING)  0 (0%!)(MISSING)
  memory             260Mi (6%!)(MISSING)  170Mi (4%!)(MISSING)
  ephemeral-storage  0 (0%!)(MISSING)      0 (0%!)(MISSING)
  hugepages-1Gi      0 (0%!)(MISSING)      0 (0%!)(MISSING)
  hugepages-2Mi      0 (0%!)(MISSING)      0 (0%!)(MISSING)
Events:
  Type    Reason                   Age    From        Message
  ----    ------                   ----   ----        -------
  Normal  Starting                 8m22s  kube-proxy  
  Normal  NodeHasSufficientMemory  8m36s  kubelet     Node ubuntu-s-2vcpu-4gb-intel-fra1-01 status is now: NodeHasSufficientMemory
  Normal  NodeHasNoDiskPressure    8m36s  kubelet     Node ubuntu-s-2vcpu-4gb-intel-fra1-01 status is now: NodeHasNoDiskPressure
  Normal  NodeHasSufficientPID     8m36s  kubelet     Node ubuntu-s-2vcpu-4gb-intel-fra1-01 status is now: NodeHasSufficientPID
  Normal  Starting                 8m36s  kubelet     Starting kubelet.
  Normal  NodeAllocatableEnforced  8m35s  kubelet     Updated Node Allocatable limit across pods
  Normal  NodeReady                8m25s  kubelet     Node ubuntu-s-2vcpu-4gb-intel-fra1-01 status is now: NodeReady

* 
* ==> dmesg <==
* [Nov 6 11:33] acpi PNP0A03:00: fail to add MMCONFIG information, can't access extended PCI configuration space under this bridge.
[  +0.565737] platform eisa.0: EISA: Cannot allocate resource for mainboard
[  +0.000805] platform eisa.0: Cannot allocate resource for EISA slot 1
[  +0.000715] platform eisa.0: Cannot allocate resource for EISA slot 2
[  +0.000730] platform eisa.0: Cannot allocate resource for EISA slot 3
[  +0.000767] platform eisa.0: Cannot allocate resource for EISA slot 4
[  +0.000731] platform eisa.0: Cannot allocate resource for EISA slot 5
[  +0.000750] platform eisa.0: Cannot allocate resource for EISA slot 6
[  +0.000765] platform eisa.0: Cannot allocate resource for EISA slot 7
[  +0.000723] platform eisa.0: Cannot allocate resource for EISA slot 8
[  +0.257630] GPT:Primary header thinks Alt. header is not at the end of the disk.
[  +0.001184] GPT:4612095 != 167772159
[  +0.000632] GPT:Alternate GPT header not at the end of the disk.
[  +0.000938] GPT:4612095 != 167772159
[  +0.000661] GPT: Use GNU Parted to correct GPT errors.
[Nov 6 11:42] kauditd_printk_skb: 9 callbacks suppressed
[Nov 6 19:14] kauditd_printk_skb: 20 callbacks suppressed
[Nov 8 18:34] vboxdrv: loading out-of-tree module taints kernel.
[  +0.004910] vboxdrv: fAsync=0 offMin=0x318 offMax=0x360e
[  +0.106271] VBoxNetFlt: Successfully started.
[  +0.005343] VBoxNetAdp: Successfully started.
[Nov 8 18:36] SUPR0GipMap: fGetGipCpu=0xb
[  +0.049813] vboxdrv: 0000000000000000 VMMR0.r0
[  +0.067954] VBoxNetFlt: attached to 'vboxnet0' / 0a:00:27:00:00:00
[  +0.037392] vboxdrv: 0000000000000000 VBoxDDR0.r0
[  +0.043444] VMMR0InitVM: eflags=246 fKernelFeatures=0x0 (SUPKERNELFEATURES_SMAP=0)
[Nov 8 18:44] vboxnetflt: 5 out of 30 packets were not sent (directed to host)

* 
* ==> etcd [e821939e19ec] <==
* {"level":"info","ts":"2021-11-09T11:03:23.106Z","caller":"etcdmain/etcd.go:72","msg":"Running: ","args":["etcd","--advertise-client-urls=https://207.154.254.97:2379","--cert-file=/var/lib/minikube/certs/etcd/server.crt","--client-cert-auth=true","--data-dir=/var/lib/minikube/etcd","--initial-advertise-peer-urls=https://207.154.254.97:2380","--initial-cluster=ubuntu-s-2vcpu-4gb-intel-fra1-01=https://207.154.254.97:2380","--key-file=/var/lib/minikube/certs/etcd/server.key","--listen-client-urls=https://127.0.0.1:2379,https://207.154.254.97:2379","--listen-metrics-urls=http://127.0.0.1:2381","--listen-peer-urls=https://207.154.254.97:2380","--name=ubuntu-s-2vcpu-4gb-intel-fra1-01","--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt","--peer-client-cert-auth=true","--peer-key-file=/var/lib/minikube/certs/etcd/peer.key","--peer-trusted-ca-file=/var/lib/minikube/certs/etcd/ca.crt","--proxy-refresh-interval=70000","--snapshot-count=10000","--trusted-ca-file=/var/lib/minikube/certs/etcd/ca.crt"]}
{"level":"info","ts":"2021-11-09T11:03:23.107Z","caller":"embed/etcd.go:131","msg":"configuring peer listeners","listen-peer-urls":["https://207.154.254.97:2380"]}
{"level":"info","ts":"2021-11-09T11:03:23.107Z","caller":"embed/etcd.go:478","msg":"starting with peer TLS","tls-info":"cert = /var/lib/minikube/certs/etcd/peer.crt, key = /var/lib/minikube/certs/etcd/peer.key, client-cert=, client-key=, trusted-ca = /var/lib/minikube/certs/etcd/ca.crt, client-cert-auth = true, crl-file = ","cipher-suites":[]}
{"level":"info","ts":"2021-11-09T11:03:23.109Z","caller":"embed/etcd.go:139","msg":"configuring client listeners","listen-client-urls":["https://127.0.0.1:2379","https://207.154.254.97:2379"]}
{"level":"info","ts":"2021-11-09T11:03:23.109Z","caller":"embed/etcd.go:307","msg":"starting an etcd server","etcd-version":"3.5.0","git-sha":"946a5a6f2","go-version":"go1.16.3","go-os":"linux","go-arch":"amd64","max-cpu-set":2,"max-cpu-available":2,"member-initialized":false,"name":"ubuntu-s-2vcpu-4gb-intel-fra1-01","data-dir":"/var/lib/minikube/etcd","wal-dir":"","wal-dir-dedicated":"","member-dir":"/var/lib/minikube/etcd/member","force-new-cluster":false,"heartbeat-interval":"100ms","election-timeout":"1s","initial-election-tick-advance":true,"snapshot-count":10000,"snapshot-catchup-entries":5000,"initial-advertise-peer-urls":["https://207.154.254.97:2380"],"listen-peer-urls":["https://207.154.254.97:2380"],"advertise-client-urls":["https://207.154.254.97:2379"],"listen-client-urls":["https://127.0.0.1:2379","https://207.154.254.97:2379"],"listen-metrics-urls":["http://127.0.0.1:2381"],"cors":["*"],"host-whitelist":["*"],"initial-cluster":"ubuntu-s-2vcpu-4gb-intel-fra1-01=https://207.154.254.97:2380","initial-cluster-state":"new","initial-cluster-token":"etcd-cluster","quota-size-bytes":2147483648,"pre-vote":true,"initial-corrupt-check":false,"corrupt-check-time-interval":"0s","auto-compaction-mode":"periodic","auto-compaction-retention":"0s","auto-compaction-interval":"0s","discovery-url":"","discovery-proxy":"","downgrade-check-interval":"5s"}
{"level":"info","ts":"2021-11-09T11:03:23.114Z","caller":"etcdserver/backend.go:81","msg":"opened backend db","path":"/var/lib/minikube/etcd/member/snap/db","took":"4.64838ms"}
{"level":"info","ts":"2021-11-09T11:03:23.124Z","caller":"etcdserver/raft.go:448","msg":"starting local member","local-member-id":"db918d2fd4dc582c","cluster-id":"fe05cde15aed767"}
{"level":"info","ts":"2021-11-09T11:03:23.124Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"db918d2fd4dc582c switched to configuration voters=()"}
{"level":"info","ts":"2021-11-09T11:03:23.124Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"db918d2fd4dc582c became follower at term 0"}
{"level":"info","ts":"2021-11-09T11:03:23.124Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"newRaft db918d2fd4dc582c [peers: [], term: 0, commit: 0, applied: 0, lastindex: 0, lastterm: 0]"}
{"level":"info","ts":"2021-11-09T11:03:23.124Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"db918d2fd4dc582c became follower at term 1"}
{"level":"info","ts":"2021-11-09T11:03:23.125Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"db918d2fd4dc582c switched to configuration voters=(15821582202503452716)"}
{"level":"warn","ts":"2021-11-09T11:03:23.131Z","caller":"auth/store.go:1220","msg":"simple token is not cryptographically signed"}
{"level":"info","ts":"2021-11-09T11:03:23.140Z","caller":"mvcc/kvstore.go:415","msg":"kvstore restored","current-rev":1}
{"level":"info","ts":"2021-11-09T11:03:23.140Z","caller":"etcdserver/quota.go:94","msg":"enabled backend quota with default value","quota-name":"v3-applier","quota-size-bytes":2147483648,"quota-size":"2.1 GB"}
{"level":"info","ts":"2021-11-09T11:03:23.142Z","caller":"etcdserver/server.go:843","msg":"starting etcd server","local-member-id":"db918d2fd4dc582c","local-server-version":"3.5.0","cluster-version":"to_be_decided"}
{"level":"info","ts":"2021-11-09T11:03:23.142Z","caller":"etcdserver/server.go:728","msg":"started as single-node; fast-forwarding election ticks","local-member-id":"db918d2fd4dc582c","forward-ticks":9,"forward-duration":"900ms","election-ticks":10,"election-timeout":"1s"}
{"level":"info","ts":"2021-11-09T11:03:23.144Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"db918d2fd4dc582c switched to configuration voters=(15821582202503452716)"}
{"level":"info","ts":"2021-11-09T11:03:23.144Z","caller":"membership/cluster.go:393","msg":"added member","cluster-id":"fe05cde15aed767","local-member-id":"db918d2fd4dc582c","added-peer-id":"db918d2fd4dc582c","added-peer-peer-urls":["https://207.154.254.97:2380"]}
{"level":"info","ts":"2021-11-09T11:03:23.154Z","caller":"embed/etcd.go:687","msg":"starting with client TLS","tls-info":"cert = /var/lib/minikube/certs/etcd/server.crt, key = /var/lib/minikube/certs/etcd/server.key, client-cert=, client-key=, trusted-ca = /var/lib/minikube/certs/etcd/ca.crt, client-cert-auth = true, crl-file = ","cipher-suites":[]}
{"level":"info","ts":"2021-11-09T11:03:23.155Z","caller":"embed/etcd.go:580","msg":"serving peer traffic","address":"207.154.254.97:2380"}
{"level":"info","ts":"2021-11-09T11:03:23.155Z","caller":"embed/etcd.go:552","msg":"cmux::serve","address":"207.154.254.97:2380"}
{"level":"info","ts":"2021-11-09T11:03:23.156Z","caller":"embed/etcd.go:276","msg":"now serving peer/client/metrics","local-member-id":"db918d2fd4dc582c","initial-advertise-peer-urls":["https://207.154.254.97:2380"],"listen-peer-urls":["https://207.154.254.97:2380"],"advertise-client-urls":["https://207.154.254.97:2379"],"listen-client-urls":["https://127.0.0.1:2379","https://207.154.254.97:2379"],"listen-metrics-urls":["http://127.0.0.1:2381"]}
{"level":"info","ts":"2021-11-09T11:03:23.156Z","caller":"embed/etcd.go:762","msg":"serving metrics","address":"http://127.0.0.1:2381"}
{"level":"info","ts":"2021-11-09T11:03:23.827Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"db918d2fd4dc582c is starting a new election at term 1"}
{"level":"info","ts":"2021-11-09T11:03:23.827Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"db918d2fd4dc582c became pre-candidate at term 1"}
{"level":"info","ts":"2021-11-09T11:03:23.827Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"db918d2fd4dc582c received MsgPreVoteResp from db918d2fd4dc582c at term 1"}
{"level":"info","ts":"2021-11-09T11:03:23.827Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"db918d2fd4dc582c became candidate at term 2"}
{"level":"info","ts":"2021-11-09T11:03:23.827Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"db918d2fd4dc582c received MsgVoteResp from db918d2fd4dc582c at term 2"}
{"level":"info","ts":"2021-11-09T11:03:23.827Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"db918d2fd4dc582c became leader at term 2"}
{"level":"info","ts":"2021-11-09T11:03:23.827Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"raft.node: db918d2fd4dc582c elected leader db918d2fd4dc582c at term 2"}
{"level":"info","ts":"2021-11-09T11:03:23.827Z","caller":"etcdserver/server.go:2476","msg":"setting up initial cluster version using v2 API","cluster-version":"3.5"}
{"level":"info","ts":"2021-11-09T11:03:23.830Z","caller":"etcdserver/server.go:2027","msg":"published local member to cluster through raft","local-member-id":"db918d2fd4dc582c","local-member-attributes":"{Name:ubuntu-s-2vcpu-4gb-intel-fra1-01 ClientURLs:[https://207.154.254.97:2379]}","request-path":"/0/members/db918d2fd4dc582c/attributes","cluster-id":"fe05cde15aed767","publish-timeout":"7s"}
{"level":"info","ts":"2021-11-09T11:03:23.830Z","caller":"membership/cluster.go:531","msg":"set initial cluster version","cluster-id":"fe05cde15aed767","local-member-id":"db918d2fd4dc582c","cluster-version":"3.5"}
{"level":"info","ts":"2021-11-09T11:03:23.830Z","caller":"api/capability.go:75","msg":"enabled capabilities for version","cluster-version":"3.5"}
{"level":"info","ts":"2021-11-09T11:03:23.830Z","caller":"etcdserver/server.go:2500","msg":"cluster version is updated","cluster-version":"3.5"}
{"level":"info","ts":"2021-11-09T11:03:23.830Z","caller":"embed/serve.go:98","msg":"ready to serve client requests"}
{"level":"info","ts":"2021-11-09T11:03:23.830Z","caller":"embed/serve.go:98","msg":"ready to serve client requests"}
{"level":"info","ts":"2021-11-09T11:03:23.832Z","caller":"embed/serve.go:188","msg":"serving client traffic securely","address":"127.0.0.1:2379"}
{"level":"info","ts":"2021-11-09T11:03:23.839Z","caller":"embed/serve.go:188","msg":"serving client traffic securely","address":"207.154.254.97:2379"}
{"level":"info","ts":"2021-11-09T11:03:23.846Z","caller":"etcdmain/main.go:47","msg":"notifying init daemon"}
{"level":"info","ts":"2021-11-09T11:03:23.846Z","caller":"etcdmain/main.go:53","msg":"successfully notified init daemon"}
{"level":"warn","ts":"2021-11-09T11:04:59.552Z","caller":"etcdserver/util.go:166","msg":"apply request took too long","took":"263.717208ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/ingress/\" range_end:\"/registry/ingress0\" count_only:true ","response":"range_response_count:0 size:5"}
{"level":"info","ts":"2021-11-09T11:04:59.552Z","caller":"traceutil/trace.go:171","msg":"trace[154847867] range","detail":"{range_begin:/registry/ingress/; range_end:/registry/ingress0; response_count:0; response_revision:676; }","duration":"264.053738ms","start":"2021-11-09T11:04:59.288Z","end":"2021-11-09T11:04:59.552Z","steps":["trace[154847867] 'count revisions from in-memory index tree'  (duration: 263.491615ms)"],"step_count":1}
{"level":"warn","ts":"2021-11-09T11:08:37.143Z","caller":"etcdserver/util.go:166","msg":"apply request took too long","took":"104.206872ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/health\" ","response":"range_response_count:0 size:5"}
{"level":"info","ts":"2021-11-09T11:08:37.144Z","caller":"traceutil/trace.go:171","msg":"trace[485395700] range","detail":"{range_begin:/registry/health; range_end:; response_count:0; response_revision:1061; }","duration":"104.644648ms","start":"2021-11-09T11:08:37.039Z","end":"2021-11-09T11:08:37.144Z","steps":["trace[485395700] 'range keys from in-memory index tree'  (duration: 104.066453ms)"],"step_count":1}
{"level":"info","ts":"2021-11-09T11:09:27.083Z","caller":"traceutil/trace.go:171","msg":"trace[59126053] linearizableReadLoop","detail":"{readStateIndex:1189; appliedIndex:1189; }","duration":"119.798822ms","start":"2021-11-09T11:09:26.964Z","end":"2021-11-09T11:09:27.083Z","steps":["trace[59126053] 'read index received'  (duration: 119.789124ms)","trace[59126053] 'applied index is now lower than readState.Index'  (duration: 8.488¬µs)"],"step_count":2}
{"level":"warn","ts":"2021-11-09T11:09:27.084Z","caller":"etcdserver/util.go:166","msg":"apply request took too long","took":"119.512524ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/ingress/default/ingress-srv\" ","response":"range_response_count:1 size:1627"}
{"level":"info","ts":"2021-11-09T11:09:27.084Z","caller":"traceutil/trace.go:171","msg":"trace[1711729941] range","detail":"{range_begin:/registry/ingress/default/ingress-srv; range_end:; response_count:1; response_revision:1104; }","duration":"119.588743ms","start":"2021-11-09T11:09:26.964Z","end":"2021-11-09T11:09:27.084Z","steps":["trace[1711729941] 'agreement among raft nodes before linearized reading'  (duration: 119.434377ms)"],"step_count":1}
{"level":"warn","ts":"2021-11-09T11:09:27.084Z","caller":"etcdserver/util.go:166","msg":"apply request took too long","took":"120.354448ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/configmaps/ingress-nginx/ingress-controller-leader\" ","response":"range_response_count:1 size:601"}
{"level":"info","ts":"2021-11-09T11:09:27.084Z","caller":"traceutil/trace.go:171","msg":"trace[1854975949] range","detail":"{range_begin:/registry/configmaps/ingress-nginx/ingress-controller-leader; range_end:; response_count:1; response_revision:1104; }","duration":"120.503284ms","start":"2021-11-09T11:09:26.964Z","end":"2021-11-09T11:09:27.084Z","steps":["trace[1854975949] 'agreement among raft nodes before linearized reading'  (duration: 119.905885ms)"],"step_count":1}
{"level":"info","ts":"2021-11-09T11:11:32.551Z","caller":"traceutil/trace.go:171","msg":"trace[381955483] linearizableReadLoop","detail":"{readStateIndex:1322; appliedIndex:1322; }","duration":"103.531285ms","start":"2021-11-09T11:11:32.447Z","end":"2021-11-09T11:11:32.551Z","steps":["trace[381955483] 'read index received'  (duration: 103.510357ms)","trace[381955483] 'applied index is now lower than readState.Index'  (duration: 19.253¬µs)"],"step_count":2}
{"level":"warn","ts":"2021-11-09T11:11:32.551Z","caller":"etcdserver/util.go:166","msg":"apply request took too long","took":"103.89453ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/ingress/\" range_end:\"/registry/ingress0\" count_only:true ","response":"range_response_count:0 size:7"}
{"level":"info","ts":"2021-11-09T11:11:32.551Z","caller":"traceutil/trace.go:171","msg":"trace[1532029961] range","detail":"{range_begin:/registry/ingress/; range_end:/registry/ingress0; response_count:0; response_revision:1211; }","duration":"103.971306ms","start":"2021-11-09T11:11:32.447Z","end":"2021-11-09T11:11:32.551Z","steps":["trace[1532029961] 'agreement among raft nodes before linearized reading'  (duration: 103.663729ms)"],"step_count":1}

* 
* ==> kernel <==
*  11:12:09 up 2 days, 23:38,  1 user,  load average: 0.29, 0.50, 0.46
Linux ubuntu-s-2vcpu-4gb-intel-fra1-01 5.4.0-88-generic #99-Ubuntu SMP Thu Sep 23 17:29:00 UTC 2021 x86_64 x86_64 x86_64 GNU/Linux
PRETTY_NAME="Ubuntu 20.04.3 LTS"

* 
* ==> kube-apiserver [b8b5c787f5f5] <==
* W1109 11:03:26.073839       1 genericapiserver.go:455] Skipping API admissionregistration.k8s.io/v1beta1 because it has no resources.
I1109 11:03:26.083395       1 plugins.go:158] Loaded 12 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestriction,TaintNodesByCondition,Priority,DefaultTolerationSeconds,DefaultStorageClass,StorageObjectInUseProtection,RuntimeClass,DefaultIngressClass,MutatingAdmissionWebhook.
I1109 11:03:26.083429       1 plugins.go:161] Loaded 11 validating admission controller(s) successfully in the following order: LimitRanger,ServiceAccount,PodSecurity,Priority,PersistentVolumeClaimResize,RuntimeClass,CertificateApproval,CertificateSigning,CertificateSubjectRestriction,ValidatingAdmissionWebhook,ResourceQuota.
W1109 11:03:26.123436       1 genericapiserver.go:455] Skipping API apiregistration.k8s.io/v1beta1 because it has no resources.
I1109 11:03:28.421485       1 dynamic_cafile_content.go:155] "Starting controller" name="request-header::/var/lib/minikube/certs/front-proxy-ca.crt"
I1109 11:03:28.421552       1 dynamic_cafile_content.go:155] "Starting controller" name="client-ca-bundle::/var/lib/minikube/certs/ca.crt"
I1109 11:03:28.422029       1 dynamic_serving_content.go:129] "Starting controller" name="serving-cert::/var/lib/minikube/certs/apiserver.crt::/var/lib/minikube/certs/apiserver.key"
I1109 11:03:28.422733       1 secure_serving.go:266] Serving securely on [::]:8443
I1109 11:03:28.423436       1 cluster_authentication_trust_controller.go:440] Starting cluster_authentication_trust_controller controller
I1109 11:03:28.423454       1 shared_informer.go:240] Waiting for caches to sync for cluster_authentication_trust_controller
I1109 11:03:28.423501       1 tlsconfig.go:240] "Starting DynamicServingCertificateController"
I1109 11:03:28.426060       1 available_controller.go:491] Starting AvailableConditionController
I1109 11:03:28.426077       1 cache.go:32] Waiting for caches to sync for AvailableConditionController controller
I1109 11:03:28.426147       1 controller.go:83] Starting OpenAPI AggregationController
I1109 11:03:28.426215       1 dynamic_cafile_content.go:155] "Starting controller" name="client-ca-bundle::/var/lib/minikube/certs/ca.crt"
I1109 11:03:28.426251       1 dynamic_cafile_content.go:155] "Starting controller" name="request-header::/var/lib/minikube/certs/front-proxy-ca.crt"
I1109 11:03:28.441113       1 apiservice_controller.go:97] Starting APIServiceRegistrationController
I1109 11:03:28.441141       1 cache.go:32] Waiting for caches to sync for APIServiceRegistrationController controller
I1109 11:03:28.441181       1 autoregister_controller.go:141] Starting autoregister controller
I1109 11:03:28.441185       1 cache.go:32] Waiting for caches to sync for autoregister controller
I1109 11:03:28.453656       1 crdregistration_controller.go:111] Starting crd-autoregister controller
I1109 11:03:28.453683       1 shared_informer.go:240] Waiting for caches to sync for crd-autoregister
I1109 11:03:28.455004       1 customresource_discovery_controller.go:209] Starting DiscoveryController
I1109 11:03:28.455071       1 apf_controller.go:312] Starting API Priority and Fairness config controller
I1109 11:03:28.455257       1 dynamic_serving_content.go:129] "Starting controller" name="aggregator-proxy-cert::/var/lib/minikube/certs/front-proxy-client.crt::/var/lib/minikube/certs/front-proxy-client.key"
I1109 11:03:28.455579       1 controller.go:85] Starting OpenAPI controller
I1109 11:03:28.455671       1 naming_controller.go:291] Starting NamingConditionController
I1109 11:03:28.455691       1 establishing_controller.go:76] Starting EstablishingController
I1109 11:03:28.455762       1 nonstructuralschema_controller.go:192] Starting NonStructuralSchemaConditionController
I1109 11:03:28.455779       1 apiapproval_controller.go:186] Starting KubernetesAPIApprovalPolicyConformantConditionController
I1109 11:03:28.455838       1 crd_finalizer.go:266] Starting CRDFinalizer
E1109 11:03:28.494324       1 controller.go:152] Unable to remove old endpoints from kubernetes service: StorageError: key not found, Code: 1, Key: /registry/masterleases/207.154.254.97, ResourceVersion: 0, AdditionalErrorMsg: 
I1109 11:03:28.589056       1 shared_informer.go:247] Caches are synced for node_authorizer 
I1109 11:03:28.624016       1 shared_informer.go:247] Caches are synced for cluster_authentication_trust_controller 
I1109 11:03:28.626382       1 cache.go:39] Caches are synced for AvailableConditionController controller
I1109 11:03:28.638493       1 controller.go:611] quota admission added evaluator for: namespaces
I1109 11:03:28.650872       1 cache.go:39] Caches are synced for autoregister controller
I1109 11:03:28.654129       1 shared_informer.go:247] Caches are synced for crd-autoregister 
I1109 11:03:28.655313       1 apf_controller.go:317] Running API Priority and Fairness config worker
I1109 11:03:28.658888       1 cache.go:39] Caches are synced for APIServiceRegistrationController controller
I1109 11:03:29.422099       1 controller.go:132] OpenAPI AggregationController: action for item : Nothing (removed from the queue).
I1109 11:03:29.422146       1 controller.go:132] OpenAPI AggregationController: action for item k8s_internal_local_delegation_chain_0000000000: Nothing (removed from the queue).
I1109 11:03:29.446269       1 storage_scheduling.go:132] created PriorityClass system-node-critical with value 2000001000
I1109 11:03:29.460170       1 storage_scheduling.go:132] created PriorityClass system-cluster-critical with value 2000000000
I1109 11:03:29.460265       1 storage_scheduling.go:148] all system priority classes are created successfully or already exist.
I1109 11:03:30.156153       1 controller.go:611] quota admission added evaluator for: roles.rbac.authorization.k8s.io
I1109 11:03:30.211557       1 controller.go:611] quota admission added evaluator for: rolebindings.rbac.authorization.k8s.io
W1109 11:03:30.381193       1 lease.go:233] Resetting endpoints for master service "kubernetes" to [207.154.254.97]
I1109 11:03:30.382597       1 controller.go:611] quota admission added evaluator for: endpoints
I1109 11:03:30.388889       1 controller.go:611] quota admission added evaluator for: endpointslices.discovery.k8s.io
I1109 11:03:30.542058       1 controller.go:611] quota admission added evaluator for: serviceaccounts
I1109 11:03:32.109595       1 controller.go:611] quota admission added evaluator for: deployments.apps
I1109 11:03:32.156516       1 controller.go:611] quota admission added evaluator for: daemonsets.apps
I1109 11:03:32.732467       1 controller.go:611] quota admission added evaluator for: leases.coordination.k8s.io
I1109 11:03:43.794675       1 controller.go:611] quota admission added evaluator for: replicasets.apps
I1109 11:03:43.842876       1 controller.go:611] quota admission added evaluator for: controllerrevisions.apps
I1109 11:03:46.526135       1 controller.go:611] quota admission added evaluator for: events.events.k8s.io
I1109 11:03:52.857439       1 controller.go:611] quota admission added evaluator for: jobs.batch
I1109 11:05:28.304186       1 controller.go:611] quota admission added evaluator for: ingresses.networking.k8s.io
I1109 11:08:15.901701       1 rest.go:387] Transition to non LoadBalancer type service or LoadBalancer type service with ExternalTrafficPolicy=Global

* 
* ==> kube-controller-manager [46d692f7c28e] <==
* I1109 11:03:43.577461       1 shared_informer.go:247] Caches are synced for PV protection 
I1109 11:03:43.588529       1 shared_informer.go:247] Caches are synced for attach detach 
I1109 11:03:43.617614       1 shared_informer.go:247] Caches are synced for persistent volume 
I1109 11:03:43.801010       1 event.go:291] "Event occurred" object="kube-system/coredns" kind="Deployment" apiVersion="apps/v1" type="Normal" reason="ScalingReplicaSet" message="Scaled up replica set coredns-78fcd69978 to 1"
I1109 11:03:43.856057       1 event.go:291] "Event occurred" object="kube-system/kube-proxy" kind="DaemonSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulCreate" message="Created pod: kube-proxy-dddlp"
I1109 11:03:44.008015       1 shared_informer.go:247] Caches are synced for garbage collector 
I1109 11:03:44.016405       1 shared_informer.go:247] Caches are synced for garbage collector 
I1109 11:03:44.016437       1 garbagecollector.go:151] Garbage collector: all resource monitors have synced. Proceeding to collect garbage
I1109 11:03:44.399293       1 event.go:291] "Event occurred" object="kube-system/coredns-78fcd69978" kind="ReplicaSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulCreate" message="Created pod: coredns-78fcd69978-6ssh6"
I1109 11:03:52.721436       1 event.go:291] "Event occurred" object="ingress-nginx/ingress-nginx-controller" kind="Deployment" apiVersion="apps/v1" type="Normal" reason="ScalingReplicaSet" message="Scaled up replica set ingress-nginx-controller-5c8d66c76d to 1"
I1109 11:03:52.758364       1 event.go:291] "Event occurred" object="ingress-nginx/ingress-nginx-controller-5c8d66c76d" kind="ReplicaSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulCreate" message="Created pod: ingress-nginx-controller-5c8d66c76d-lp8zl"
I1109 11:03:52.863212       1 job_controller.go:406] enqueueing job ingress-nginx/ingress-nginx-admission-create
I1109 11:03:52.878723       1 job_controller.go:406] enqueueing job ingress-nginx/ingress-nginx-admission-patch
I1109 11:03:52.886551       1 job_controller.go:406] enqueueing job ingress-nginx/ingress-nginx-admission-patch
I1109 11:03:52.887029       1 job_controller.go:406] enqueueing job ingress-nginx/ingress-nginx-admission-create
I1109 11:03:52.889749       1 event.go:291] "Event occurred" object="ingress-nginx/ingress-nginx-admission-create" kind="Job" apiVersion="batch/v1" type="Normal" reason="SuccessfulCreate" message="Created pod: ingress-nginx-admission-create--1-m9skj"
I1109 11:03:52.889806       1 event.go:291] "Event occurred" object="ingress-nginx/ingress-nginx-admission-patch" kind="Job" apiVersion="batch/v1" type="Normal" reason="SuccessfulCreate" message="Created pod: ingress-nginx-admission-patch--1-4hjr9"
I1109 11:03:52.905273       1 job_controller.go:406] enqueueing job ingress-nginx/ingress-nginx-admission-create
I1109 11:03:52.905513       1 job_controller.go:406] enqueueing job ingress-nginx/ingress-nginx-admission-patch
I1109 11:03:52.905894       1 job_controller.go:406] enqueueing job ingress-nginx/ingress-nginx-admission-create
I1109 11:03:52.922228       1 job_controller.go:406] enqueueing job ingress-nginx/ingress-nginx-admission-patch
I1109 11:03:52.932521       1 job_controller.go:406] enqueueing job ingress-nginx/ingress-nginx-admission-patch
I1109 11:03:52.951820       1 job_controller.go:406] enqueueing job ingress-nginx/ingress-nginx-admission-create
I1109 11:03:55.473217       1 job_controller.go:406] enqueueing job ingress-nginx/ingress-nginx-admission-create
I1109 11:03:55.474024       1 event.go:291] "Event occurred" object="ingress-nginx/ingress-nginx-admission-create" kind="Job" apiVersion="batch/v1" type="Normal" reason="Completed" message="Job completed"
I1109 11:03:55.494553       1 job_controller.go:406] enqueueing job ingress-nginx/ingress-nginx-admission-create
I1109 11:03:55.518127       1 job_controller.go:406] enqueueing job ingress-nginx/ingress-nginx-admission-patch
I1109 11:03:56.524915       1 job_controller.go:406] enqueueing job ingress-nginx/ingress-nginx-admission-patch
I1109 11:03:56.525549       1 event.go:291] "Event occurred" object="ingress-nginx/ingress-nginx-admission-patch" kind="Job" apiVersion="batch/v1" type="Normal" reason="Completed" message="Job completed"
I1109 11:03:56.534299       1 job_controller.go:406] enqueueing job ingress-nginx/ingress-nginx-admission-patch
I1109 11:03:57.605895       1 job_controller.go:406] enqueueing job ingress-nginx/ingress-nginx-admission-patch
I1109 11:04:48.148584       1 event.go:291] "Event occurred" object="default/nats-depl" kind="Deployment" apiVersion="apps/v1" type="Normal" reason="ScalingReplicaSet" message="Scaled up replica set nats-depl-6bd8d44b6f to 1"
I1109 11:04:48.164190       1 event.go:291] "Event occurred" object="default/nats-depl-6bd8d44b6f" kind="ReplicaSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulCreate" message="Created pod: nats-depl-6bd8d44b6f-w5p4w"
I1109 11:04:54.315010       1 event.go:291] "Event occurred" object="default/users-depl" kind="Deployment" apiVersion="apps/v1" type="Normal" reason="ScalingReplicaSet" message="Scaled up replica set users-depl-7cdfd8447d to 1"
I1109 11:04:54.325860       1 event.go:291] "Event occurred" object="default/users-depl-7cdfd8447d" kind="ReplicaSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulCreate" message="Created pod: users-depl-7cdfd8447d-45zvh"
I1109 11:05:03.329914       1 event.go:291] "Event occurred" object="default/videos-depl" kind="Deployment" apiVersion="apps/v1" type="Normal" reason="ScalingReplicaSet" message="Scaled up replica set videos-depl-569b4b45bd to 1"
I1109 11:05:03.338547       1 event.go:291] "Event occurred" object="default/videos-depl-569b4b45bd" kind="ReplicaSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulCreate" message="Created pod: videos-depl-569b4b45bd-k46sh"
I1109 11:05:15.672677       1 event.go:291] "Event occurred" object="default/query-depl" kind="Deployment" apiVersion="apps/v1" type="Normal" reason="ScalingReplicaSet" message="Scaled up replica set query-depl-d6f444ffd to 1"
I1109 11:05:15.681955       1 event.go:291] "Event occurred" object="default/query-depl-d6f444ffd" kind="ReplicaSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulCreate" message="Created pod: query-depl-d6f444ffd-8lvc2"
I1109 11:07:40.688768       1 event.go:291] "Event occurred" object="kubernetes-dashboard/dashboard-metrics-scraper" kind="Deployment" apiVersion="apps/v1" type="Normal" reason="ScalingReplicaSet" message="Scaled up replica set dashboard-metrics-scraper-5594458c94 to 1"
I1109 11:07:40.704734       1 event.go:291] "Event occurred" object="kubernetes-dashboard/dashboard-metrics-scraper-5594458c94" kind="ReplicaSet" apiVersion="apps/v1" type="Warning" reason="FailedCreate" message="Error creating: pods \"dashboard-metrics-scraper-5594458c94-\" is forbidden: error looking up service account kubernetes-dashboard/kubernetes-dashboard: serviceaccount \"kubernetes-dashboard\" not found"
I1109 11:07:40.711692       1 event.go:291] "Event occurred" object="kubernetes-dashboard/kubernetes-dashboard" kind="Deployment" apiVersion="apps/v1" type="Normal" reason="ScalingReplicaSet" message="Scaled up replica set kubernetes-dashboard-654cf69797 to 1"
I1109 11:07:40.723313       1 event.go:291] "Event occurred" object="kubernetes-dashboard/kubernetes-dashboard-654cf69797" kind="ReplicaSet" apiVersion="apps/v1" type="Warning" reason="FailedCreate" message="Error creating: pods \"kubernetes-dashboard-654cf69797-\" is forbidden: error looking up service account kubernetes-dashboard/kubernetes-dashboard: serviceaccount \"kubernetes-dashboard\" not found"
E1109 11:07:40.735394       1 replica_set.go:536] sync "kubernetes-dashboard/dashboard-metrics-scraper-5594458c94" failed with pods "dashboard-metrics-scraper-5594458c94-" is forbidden: error looking up service account kubernetes-dashboard/kubernetes-dashboard: serviceaccount "kubernetes-dashboard" not found
E1109 11:07:40.742440       1 replica_set.go:536] sync "kubernetes-dashboard/kubernetes-dashboard-654cf69797" failed with pods "kubernetes-dashboard-654cf69797-" is forbidden: error looking up service account kubernetes-dashboard/kubernetes-dashboard: serviceaccount "kubernetes-dashboard" not found
E1109 11:07:40.758562       1 replica_set.go:536] sync "kubernetes-dashboard/dashboard-metrics-scraper-5594458c94" failed with pods "dashboard-metrics-scraper-5594458c94-" is forbidden: error looking up service account kubernetes-dashboard/kubernetes-dashboard: serviceaccount "kubernetes-dashboard" not found
I1109 11:07:40.759558       1 event.go:291] "Event occurred" object="kubernetes-dashboard/dashboard-metrics-scraper-5594458c94" kind="ReplicaSet" apiVersion="apps/v1" type="Warning" reason="FailedCreate" message="Error creating: pods \"dashboard-metrics-scraper-5594458c94-\" is forbidden: error looking up service account kubernetes-dashboard/kubernetes-dashboard: serviceaccount \"kubernetes-dashboard\" not found"
E1109 11:07:40.764716       1 replica_set.go:536] sync "kubernetes-dashboard/kubernetes-dashboard-654cf69797" failed with pods "kubernetes-dashboard-654cf69797-" is forbidden: error looking up service account kubernetes-dashboard/kubernetes-dashboard: serviceaccount "kubernetes-dashboard" not found
I1109 11:07:40.765523       1 event.go:291] "Event occurred" object="kubernetes-dashboard/kubernetes-dashboard-654cf69797" kind="ReplicaSet" apiVersion="apps/v1" type="Warning" reason="FailedCreate" message="Error creating: pods \"kubernetes-dashboard-654cf69797-\" is forbidden: error looking up service account kubernetes-dashboard/kubernetes-dashboard: serviceaccount \"kubernetes-dashboard\" not found"
I1109 11:07:40.771014       1 event.go:291] "Event occurred" object="kubernetes-dashboard/dashboard-metrics-scraper-5594458c94" kind="ReplicaSet" apiVersion="apps/v1" type="Warning" reason="FailedCreate" message="Error creating: pods \"dashboard-metrics-scraper-5594458c94-\" is forbidden: error looking up service account kubernetes-dashboard/kubernetes-dashboard: serviceaccount \"kubernetes-dashboard\" not found"
E1109 11:07:40.771262       1 replica_set.go:536] sync "kubernetes-dashboard/dashboard-metrics-scraper-5594458c94" failed with pods "dashboard-metrics-scraper-5594458c94-" is forbidden: error looking up service account kubernetes-dashboard/kubernetes-dashboard: serviceaccount "kubernetes-dashboard" not found
E1109 11:07:40.777799       1 replica_set.go:536] sync "kubernetes-dashboard/kubernetes-dashboard-654cf69797" failed with pods "kubernetes-dashboard-654cf69797-" is forbidden: error looking up service account kubernetes-dashboard/kubernetes-dashboard: serviceaccount "kubernetes-dashboard" not found
I1109 11:07:40.778940       1 event.go:291] "Event occurred" object="kubernetes-dashboard/kubernetes-dashboard-654cf69797" kind="ReplicaSet" apiVersion="apps/v1" type="Warning" reason="FailedCreate" message="Error creating: pods \"kubernetes-dashboard-654cf69797-\" is forbidden: error looking up service account kubernetes-dashboard/kubernetes-dashboard: serviceaccount \"kubernetes-dashboard\" not found"
I1109 11:07:40.793581       1 event.go:291] "Event occurred" object="kubernetes-dashboard/kubernetes-dashboard-654cf69797" kind="ReplicaSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulCreate" message="Created pod: kubernetes-dashboard-654cf69797-n4d2t"
I1109 11:07:40.795035       1 event.go:291] "Event occurred" object="kubernetes-dashboard/dashboard-metrics-scraper-5594458c94" kind="ReplicaSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulCreate" message="Created pod: dashboard-metrics-scraper-5594458c94-5d9kh"
I1109 11:08:15.908950       1 event.go:291] "Event occurred" object="ingress-nginx/ingress-nginx-controller" kind="Service" apiVersion="v1" type="Normal" reason="Type" message="LoadBalancer -> NodePort"
I1109 11:08:15.993112       1 event.go:291] "Event occurred" object="ingress-nginx/ingress-nginx-controller" kind="Deployment" apiVersion="apps/v1" type="Normal" reason="ScalingReplicaSet" message="Scaled up replica set ingress-nginx-controller-5f66978484 to 1"
I1109 11:08:16.027325       1 event.go:291] "Event occurred" object="ingress-nginx/ingress-nginx-controller-5f66978484" kind="ReplicaSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulCreate" message="Created pod: ingress-nginx-controller-5f66978484-w8qm7"
I1109 11:08:36.109119       1 event.go:291] "Event occurred" object="ingress-nginx/ingress-nginx-controller" kind="Deployment" apiVersion="apps/v1" type="Normal" reason="ScalingReplicaSet" message="Scaled down replica set ingress-nginx-controller-5c8d66c76d to 0"
I1109 11:08:36.141379       1 event.go:291] "Event occurred" object="ingress-nginx/ingress-nginx-controller-5c8d66c76d" kind="ReplicaSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulDelete" message="Deleted pod: ingress-nginx-controller-5c8d66c76d-lp8zl"

* 
* ==> kube-proxy [83b4b51dcb97] <==
* I1109 11:03:46.344817       1 node.go:172] Successfully retrieved node IP: 207.154.254.97
I1109 11:03:46.344897       1 server_others.go:140] Detected node IP 207.154.254.97
W1109 11:03:46.344967       1 server_others.go:565] Unknown proxy mode "", assuming iptables proxy
I1109 11:03:46.446917       1 server_others.go:206] kube-proxy running in dual-stack mode, IPv4-primary
I1109 11:03:46.446953       1 server_others.go:212] Using iptables Proxier.
I1109 11:03:46.446965       1 server_others.go:219] creating dualStackProxier for iptables.
W1109 11:03:46.446985       1 server_others.go:495] detect-local-mode set to ClusterCIDR, but no IPv6 cluster CIDR defined, , defaulting to no-op detect-local for IPv6
I1109 11:03:46.453150       1 server.go:649] Version: v1.22.3
I1109 11:03:46.482881       1 config.go:315] Starting service config controller
I1109 11:03:46.482919       1 shared_informer.go:240] Waiting for caches to sync for service config
I1109 11:03:46.482962       1 config.go:224] Starting endpoint slice config controller
I1109 11:03:46.482967       1 shared_informer.go:240] Waiting for caches to sync for endpoint slice config
I1109 11:03:46.583597       1 shared_informer.go:247] Caches are synced for endpoint slice config 
I1109 11:03:46.583651       1 shared_informer.go:247] Caches are synced for service config 

* 
* ==> kube-scheduler [9a2d7e6450d1] <==
* I1109 11:03:23.778615       1 serving.go:347] Generated self-signed cert in-memory
W1109 11:03:28.520796       1 requestheader_controller.go:193] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W1109 11:03:28.520917       1 authentication.go:345] Error looking up in-cluster authentication configuration: configmaps "extension-apiserver-authentication" is forbidden: User "system:kube-scheduler" cannot get resource "configmaps" in API group "" in the namespace "kube-system"
W1109 11:03:28.520967       1 authentication.go:346] Continuing without authentication configuration. This may treat all requests as anonymous.
W1109 11:03:28.520998       1 authentication.go:347] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I1109 11:03:28.565981       1 secure_serving.go:200] Serving securely on 127.0.0.1:10259
I1109 11:03:28.569615       1 configmap_cafile_content.go:201] "Starting controller" name="client-ca::kube-system::extension-apiserver-authentication::client-ca-file"
I1109 11:03:28.572963       1 shared_informer.go:240] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
E1109 11:03:28.582145       1 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.StatefulSet: failed to list *v1.StatefulSet: statefulsets.apps is forbidden: User "system:kube-scheduler" cannot list resource "statefulsets" in API group "apps" at the cluster scope
I1109 11:03:28.569804       1 tlsconfig.go:240] "Starting DynamicServingCertificateController"
E1109 11:03:28.583405       1 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.Namespace: failed to list *v1.Namespace: namespaces is forbidden: User "system:kube-scheduler" cannot list resource "namespaces" in API group "" at the cluster scope
E1109 11:03:28.583595       1 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.ReplicationController: failed to list *v1.ReplicationController: replicationcontrollers is forbidden: User "system:kube-scheduler" cannot list resource "replicationcontrollers" in API group "" at the cluster scope
E1109 11:03:28.587965       1 reflector.go:138] k8s.io/apiserver/pkg/server/dynamiccertificates/configmap_cafile_content.go:205: Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: configmaps "extension-apiserver-authentication" is forbidden: User "system:kube-scheduler" cannot list resource "configmaps" in API group "" in the namespace "kube-system"
E1109 11:03:28.588853       1 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.Pod: failed to list *v1.Pod: pods is forbidden: User "system:kube-scheduler" cannot list resource "pods" in API group "" at the cluster scope
E1109 11:03:28.589948       1 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.Node: failed to list *v1.Node: nodes is forbidden: User "system:kube-scheduler" cannot list resource "nodes" in API group "" at the cluster scope
E1109 11:03:28.590203       1 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.PersistentVolumeClaim: failed to list *v1.PersistentVolumeClaim: persistentvolumeclaims is forbidden: User "system:kube-scheduler" cannot list resource "persistentvolumeclaims" in API group "" at the cluster scope
E1109 11:03:28.590397       1 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.Service: failed to list *v1.Service: services is forbidden: User "system:kube-scheduler" cannot list resource "services" in API group "" at the cluster scope
E1109 11:03:28.590579       1 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.CSINode: failed to list *v1.CSINode: csinodes.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "csinodes" in API group "storage.k8s.io" at the cluster scope
E1109 11:03:28.590600       1 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.PersistentVolume: failed to list *v1.PersistentVolume: persistentvolumes is forbidden: User "system:kube-scheduler" cannot list resource "persistentvolumes" in API group "" at the cluster scope
E1109 11:03:28.590808       1 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.CSIDriver: failed to list *v1.CSIDriver: csidrivers.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "csidrivers" in API group "storage.k8s.io" at the cluster scope
E1109 11:03:28.591016       1 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.StorageClass: failed to list *v1.StorageClass: storageclasses.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "storageclasses" in API group "storage.k8s.io" at the cluster scope
E1109 11:03:28.591193       1 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.ReplicaSet: failed to list *v1.ReplicaSet: replicasets.apps is forbidden: User "system:kube-scheduler" cannot list resource "replicasets" in API group "apps" at the cluster scope
E1109 11:03:28.591515       1 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.PodDisruptionBudget: failed to list *v1.PodDisruptionBudget: poddisruptionbudgets.policy is forbidden: User "system:kube-scheduler" cannot list resource "poddisruptionbudgets" in API group "policy" at the cluster scope
E1109 11:03:28.591739       1 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1beta1.CSIStorageCapacity: failed to list *v1beta1.CSIStorageCapacity: csistoragecapacities.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "csistoragecapacities" in API group "storage.k8s.io" at the cluster scope
E1109 11:03:29.456089       1 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.Node: failed to list *v1.Node: nodes is forbidden: User "system:kube-scheduler" cannot list resource "nodes" in API group "" at the cluster scope
E1109 11:03:29.533483       1 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1beta1.CSIStorageCapacity: failed to list *v1beta1.CSIStorageCapacity: csistoragecapacities.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "csistoragecapacities" in API group "storage.k8s.io" at the cluster scope
E1109 11:03:29.553944       1 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.PodDisruptionBudget: failed to list *v1.PodDisruptionBudget: poddisruptionbudgets.policy is forbidden: User "system:kube-scheduler" cannot list resource "poddisruptionbudgets" in API group "policy" at the cluster scope
E1109 11:03:29.561435       1 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.StatefulSet: failed to list *v1.StatefulSet: statefulsets.apps is forbidden: User "system:kube-scheduler" cannot list resource "statefulsets" in API group "apps" at the cluster scope
E1109 11:03:29.660502       1 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.Service: failed to list *v1.Service: services is forbidden: User "system:kube-scheduler" cannot list resource "services" in API group "" at the cluster scope
E1109 11:03:29.704405       1 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.PersistentVolumeClaim: failed to list *v1.PersistentVolumeClaim: persistentvolumeclaims is forbidden: User "system:kube-scheduler" cannot list resource "persistentvolumeclaims" in API group "" at the cluster scope
E1109 11:03:29.729625       1 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.CSIDriver: failed to list *v1.CSIDriver: csidrivers.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "csidrivers" in API group "storage.k8s.io" at the cluster scope
E1109 11:03:29.758818       1 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.Namespace: failed to list *v1.Namespace: namespaces is forbidden: User "system:kube-scheduler" cannot list resource "namespaces" in API group "" at the cluster scope
E1109 11:03:29.825670       1 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.ReplicaSet: failed to list *v1.ReplicaSet: replicasets.apps is forbidden: User "system:kube-scheduler" cannot list resource "replicasets" in API group "apps" at the cluster scope
E1109 11:03:29.834232       1 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.StorageClass: failed to list *v1.StorageClass: storageclasses.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "storageclasses" in API group "storage.k8s.io" at the cluster scope
E1109 11:03:29.882860       1 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.CSINode: failed to list *v1.CSINode: csinodes.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "csinodes" in API group "storage.k8s.io" at the cluster scope
E1109 11:03:29.901655       1 reflector.go:138] k8s.io/apiserver/pkg/server/dynamiccertificates/configmap_cafile_content.go:205: Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: configmaps "extension-apiserver-authentication" is forbidden: User "system:kube-scheduler" cannot list resource "configmaps" in API group "" in the namespace "kube-system"
E1109 11:03:30.324914       1 plugin.go:138] "getting namespace, assuming empty set of namespace labels" err="namespace \"kube-system\" not found" namespace="kube-system"
E1109 11:03:31.607280       1 plugin.go:138] "getting namespace, assuming empty set of namespace labels" err="namespace \"kube-system\" not found" namespace="kube-system"
I1109 11:03:32.273582       1 shared_informer.go:247] Caches are synced for client-ca::kube-system::extension-apiserver-authentication::client-ca-file 

* 
* ==> kubelet <==
* -- Logs begin at Sat 2021-11-06 11:33:41 UTC, end at Tue 2021-11-09 11:12:09 UTC. --
Nov 09 11:03:57 ubuntu-s-2vcpu-4gb-intel-fra1-01 kubelet[1056728]: I1109 11:03:57.756188 1056728 operation_generator.go:866] UnmountVolume.TearDown succeeded for volume "kubernetes.io/projected/f1393e61-6468-46b8-92ab-2c5bbcc60a3b-kube-api-access-4frgj" (OuterVolumeSpecName: "kube-api-access-4frgj") pod "f1393e61-6468-46b8-92ab-2c5bbcc60a3b" (UID: "f1393e61-6468-46b8-92ab-2c5bbcc60a3b"). InnerVolumeSpecName "kube-api-access-4frgj". PluginName "kubernetes.io/projected", VolumeGidValue ""
Nov 09 11:03:57 ubuntu-s-2vcpu-4gb-intel-fra1-01 kubelet[1056728]: I1109 11:03:57.849782 1056728 reconciler.go:319] "Volume detached for volume \"kube-api-access-4frgj\" (UniqueName: \"kubernetes.io/projected/f1393e61-6468-46b8-92ab-2c5bbcc60a3b-kube-api-access-4frgj\") on node \"ubuntu-s-2vcpu-4gb-intel-fra1-01\" DevicePath \"\""
Nov 09 11:03:58 ubuntu-s-2vcpu-4gb-intel-fra1-01 kubelet[1056728]: I1109 11:03:58.755883 1056728 reconciler.go:196] "operationExecutor.UnmountVolume started for volume \"kube-api-access-c2hvs\" (UniqueName: \"kubernetes.io/projected/9a255ef3-80e7-4a14-ac79-3d114811dd5d-kube-api-access-c2hvs\") pod \"9a255ef3-80e7-4a14-ac79-3d114811dd5d\" (UID: \"9a255ef3-80e7-4a14-ac79-3d114811dd5d\") "
Nov 09 11:03:58 ubuntu-s-2vcpu-4gb-intel-fra1-01 kubelet[1056728]: I1109 11:03:58.762331 1056728 operation_generator.go:866] UnmountVolume.TearDown succeeded for volume "kubernetes.io/projected/9a255ef3-80e7-4a14-ac79-3d114811dd5d-kube-api-access-c2hvs" (OuterVolumeSpecName: "kube-api-access-c2hvs") pod "9a255ef3-80e7-4a14-ac79-3d114811dd5d" (UID: "9a255ef3-80e7-4a14-ac79-3d114811dd5d"). InnerVolumeSpecName "kube-api-access-c2hvs". PluginName "kubernetes.io/projected", VolumeGidValue ""
Nov 09 11:03:58 ubuntu-s-2vcpu-4gb-intel-fra1-01 kubelet[1056728]: I1109 11:03:58.856684 1056728 reconciler.go:319] "Volume detached for volume \"kube-api-access-c2hvs\" (UniqueName: \"kubernetes.io/projected/9a255ef3-80e7-4a14-ac79-3d114811dd5d-kube-api-access-c2hvs\") on node \"ubuntu-s-2vcpu-4gb-intel-fra1-01\" DevicePath \"\""
Nov 09 11:04:03 ubuntu-s-2vcpu-4gb-intel-fra1-01 kubelet[1056728]: E1109 11:04:03.184492 1056728 cadvisor_stats_provider.go:415] "Partial failure issuing cadvisor.ContainerInfoV2" err="partial failures: [\"/kubepods/burstable/podf8bb9d8d-0320-4c18-803f-c4f934e6a19b\": RecentStats: unable to find data in memory cache]"
Nov 09 11:04:48 ubuntu-s-2vcpu-4gb-intel-fra1-01 kubelet[1056728]: I1109 11:04:48.167376 1056728 topology_manager.go:200] "Topology Admit Handler"
Nov 09 11:04:48 ubuntu-s-2vcpu-4gb-intel-fra1-01 kubelet[1056728]: I1109 11:04:48.292659 1056728 reconciler.go:224] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-tnmd6\" (UniqueName: \"kubernetes.io/projected/64060ebb-ec0e-4116-bc18-5f25fe5aaeeb-kube-api-access-tnmd6\") pod \"nats-depl-6bd8d44b6f-w5p4w\" (UID: \"64060ebb-ec0e-4116-bc18-5f25fe5aaeeb\") "
Nov 09 11:04:49 ubuntu-s-2vcpu-4gb-intel-fra1-01 kubelet[1056728]: I1109 11:04:49.218464 1056728 docker_sandbox.go:401] "Failed to read pod IP from plugin/docker" err="Couldn't find network status for default/nats-depl-6bd8d44b6f-w5p4w through plugin: invalid network status for"
Nov 09 11:04:49 ubuntu-s-2vcpu-4gb-intel-fra1-01 kubelet[1056728]: I1109 11:04:49.219840 1056728 pod_container_deletor.go:79] "Container not found in pod's containers" containerID="8f5819261b6c2a3185aeee330eb86843de70421ce6fc0cdc7e18eab9b11698fc"
Nov 09 11:04:50 ubuntu-s-2vcpu-4gb-intel-fra1-01 kubelet[1056728]: I1109 11:04:50.228280 1056728 docker_sandbox.go:401] "Failed to read pod IP from plugin/docker" err="Couldn't find network status for default/nats-depl-6bd8d44b6f-w5p4w through plugin: invalid network status for"
Nov 09 11:04:54 ubuntu-s-2vcpu-4gb-intel-fra1-01 kubelet[1056728]: I1109 11:04:54.333263 1056728 topology_manager.go:200] "Topology Admit Handler"
Nov 09 11:04:54 ubuntu-s-2vcpu-4gb-intel-fra1-01 kubelet[1056728]: W1109 11:04:54.356082 1056728 container.go:586] Failed to update stats for container "/kubepods/besteffort/pod71941977-4952-42fd-99ec-24a0ba4e315e": /sys/fs/cgroup/cpuset/kubepods/besteffort/pod71941977-4952-42fd-99ec-24a0ba4e315e/cpuset.cpus found to be empty, continuing to push stats
Nov 09 11:04:54 ubuntu-s-2vcpu-4gb-intel-fra1-01 kubelet[1056728]: I1109 11:04:54.443442 1056728 reconciler.go:224] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-9j9kx\" (UniqueName: \"kubernetes.io/projected/71941977-4952-42fd-99ec-24a0ba4e315e-kube-api-access-9j9kx\") pod \"users-depl-7cdfd8447d-45zvh\" (UID: \"71941977-4952-42fd-99ec-24a0ba4e315e\") "
Nov 09 11:04:55 ubuntu-s-2vcpu-4gb-intel-fra1-01 kubelet[1056728]: I1109 11:04:55.224101 1056728 docker_sandbox.go:401] "Failed to read pod IP from plugin/docker" err="Couldn't find network status for default/users-depl-7cdfd8447d-45zvh through plugin: invalid network status for"
Nov 09 11:04:55 ubuntu-s-2vcpu-4gb-intel-fra1-01 kubelet[1056728]: I1109 11:04:55.270810 1056728 docker_sandbox.go:401] "Failed to read pod IP from plugin/docker" err="Couldn't find network status for default/users-depl-7cdfd8447d-45zvh through plugin: invalid network status for"
Nov 09 11:04:57 ubuntu-s-2vcpu-4gb-intel-fra1-01 kubelet[1056728]: I1109 11:04:57.292008 1056728 docker_sandbox.go:401] "Failed to read pod IP from plugin/docker" err="Couldn't find network status for default/users-depl-7cdfd8447d-45zvh through plugin: invalid network status for"
Nov 09 11:05:03 ubuntu-s-2vcpu-4gb-intel-fra1-01 kubelet[1056728]: I1109 11:05:03.370277 1056728 topology_manager.go:200] "Topology Admit Handler"
Nov 09 11:05:03 ubuntu-s-2vcpu-4gb-intel-fra1-01 kubelet[1056728]: E1109 11:05:03.425325 1056728 cadvisor_stats_provider.go:415] "Partial failure issuing cadvisor.ContainerInfoV2" err="partial failures: [\"/kubepods/besteffort/pod71941977-4952-42fd-99ec-24a0ba4e315e\": RecentStats: unable to find data in memory cache]"
Nov 09 11:05:03 ubuntu-s-2vcpu-4gb-intel-fra1-01 kubelet[1056728]: I1109 11:05:03.512128 1056728 reconciler.go:224] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-6l4f8\" (UniqueName: \"kubernetes.io/projected/c546c002-091a-4b24-b347-f3583c1cd01d-kube-api-access-6l4f8\") pod \"videos-depl-569b4b45bd-k46sh\" (UID: \"c546c002-091a-4b24-b347-f3583c1cd01d\") "
Nov 09 11:05:04 ubuntu-s-2vcpu-4gb-intel-fra1-01 kubelet[1056728]: I1109 11:05:04.252522 1056728 docker_sandbox.go:401] "Failed to read pod IP from plugin/docker" err="Couldn't find network status for default/videos-depl-569b4b45bd-k46sh through plugin: invalid network status for"
Nov 09 11:05:04 ubuntu-s-2vcpu-4gb-intel-fra1-01 kubelet[1056728]: I1109 11:05:04.373670 1056728 docker_sandbox.go:401] "Failed to read pod IP from plugin/docker" err="Couldn't find network status for default/videos-depl-569b4b45bd-k46sh through plugin: invalid network status for"
Nov 09 11:05:06 ubuntu-s-2vcpu-4gb-intel-fra1-01 kubelet[1056728]: I1109 11:05:06.396516 1056728 docker_sandbox.go:401] "Failed to read pod IP from plugin/docker" err="Couldn't find network status for default/videos-depl-569b4b45bd-k46sh through plugin: invalid network status for"
Nov 09 11:05:15 ubuntu-s-2vcpu-4gb-intel-fra1-01 kubelet[1056728]: I1109 11:05:15.687375 1056728 topology_manager.go:200] "Topology Admit Handler"
Nov 09 11:05:15 ubuntu-s-2vcpu-4gb-intel-fra1-01 kubelet[1056728]: I1109 11:05:15.793260 1056728 reconciler.go:224] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-5ln8j\" (UniqueName: \"kubernetes.io/projected/1c32a68d-660f-4ec9-9965-76d834fdf38a-kube-api-access-5ln8j\") pod \"query-depl-d6f444ffd-8lvc2\" (UID: \"1c32a68d-660f-4ec9-9965-76d834fdf38a\") "
Nov 09 11:05:16 ubuntu-s-2vcpu-4gb-intel-fra1-01 kubelet[1056728]: I1109 11:05:16.557940 1056728 pod_container_deletor.go:79] "Container not found in pod's containers" containerID="62924fc037e66a4505cb0f69a59e4d10afc5a65f3cc8b22da14ab9685fa68716"
Nov 09 11:05:16 ubuntu-s-2vcpu-4gb-intel-fra1-01 kubelet[1056728]: I1109 11:05:16.558163 1056728 docker_sandbox.go:401] "Failed to read pod IP from plugin/docker" err="Couldn't find network status for default/query-depl-d6f444ffd-8lvc2 through plugin: invalid network status for"
Nov 09 11:05:17 ubuntu-s-2vcpu-4gb-intel-fra1-01 kubelet[1056728]: I1109 11:05:17.568016 1056728 docker_sandbox.go:401] "Failed to read pod IP from plugin/docker" err="Couldn't find network status for default/query-depl-d6f444ffd-8lvc2 through plugin: invalid network status for"
Nov 09 11:05:18 ubuntu-s-2vcpu-4gb-intel-fra1-01 kubelet[1056728]: I1109 11:05:18.581918 1056728 docker_sandbox.go:401] "Failed to read pod IP from plugin/docker" err="Couldn't find network status for default/query-depl-d6f444ffd-8lvc2 through plugin: invalid network status for"
Nov 09 11:07:40 ubuntu-s-2vcpu-4gb-intel-fra1-01 kubelet[1056728]: I1109 11:07:40.809284 1056728 topology_manager.go:200] "Topology Admit Handler"
Nov 09 11:07:40 ubuntu-s-2vcpu-4gb-intel-fra1-01 kubelet[1056728]: I1109 11:07:40.816451 1056728 topology_manager.go:200] "Topology Admit Handler"
Nov 09 11:07:40 ubuntu-s-2vcpu-4gb-intel-fra1-01 kubelet[1056728]: I1109 11:07:40.823291 1056728 reconciler.go:224] "operationExecutor.VerifyControllerAttachedVolume started for volume \"tmp-volume\" (UniqueName: \"kubernetes.io/empty-dir/aee4b048-badc-47a6-848a-1d0f1f284aa0-tmp-volume\") pod \"kubernetes-dashboard-654cf69797-n4d2t\" (UID: \"aee4b048-badc-47a6-848a-1d0f1f284aa0\") "
Nov 09 11:07:40 ubuntu-s-2vcpu-4gb-intel-fra1-01 kubelet[1056728]: I1109 11:07:40.823734 1056728 reconciler.go:224] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-xdl25\" (UniqueName: \"kubernetes.io/projected/aee4b048-badc-47a6-848a-1d0f1f284aa0-kube-api-access-xdl25\") pod \"kubernetes-dashboard-654cf69797-n4d2t\" (UID: \"aee4b048-badc-47a6-848a-1d0f1f284aa0\") "
Nov 09 11:07:40 ubuntu-s-2vcpu-4gb-intel-fra1-01 kubelet[1056728]: W1109 11:07:40.867909 1056728 container.go:586] Failed to update stats for container "/kubepods/besteffort/podaee4b048-badc-47a6-848a-1d0f1f284aa0": /sys/fs/cgroup/cpuset/kubepods/besteffort/podaee4b048-badc-47a6-848a-1d0f1f284aa0/cpuset.cpus found to be empty, continuing to push stats
Nov 09 11:07:40 ubuntu-s-2vcpu-4gb-intel-fra1-01 kubelet[1056728]: I1109 11:07:40.925214 1056728 reconciler.go:224] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-n8v2r\" (UniqueName: \"kubernetes.io/projected/b83cab05-ba47-4667-ba8c-0469b4c69b87-kube-api-access-n8v2r\") pod \"dashboard-metrics-scraper-5594458c94-5d9kh\" (UID: \"b83cab05-ba47-4667-ba8c-0469b4c69b87\") "
Nov 09 11:07:40 ubuntu-s-2vcpu-4gb-intel-fra1-01 kubelet[1056728]: I1109 11:07:40.925684 1056728 reconciler.go:224] "operationExecutor.VerifyControllerAttachedVolume started for volume \"tmp-volume\" (UniqueName: \"kubernetes.io/empty-dir/b83cab05-ba47-4667-ba8c-0469b4c69b87-tmp-volume\") pod \"dashboard-metrics-scraper-5594458c94-5d9kh\" (UID: \"b83cab05-ba47-4667-ba8c-0469b4c69b87\") "
Nov 09 11:07:42 ubuntu-s-2vcpu-4gb-intel-fra1-01 kubelet[1056728]: I1109 11:07:42.024018 1056728 pod_container_deletor.go:79] "Container not found in pod's containers" containerID="29a73c73698a78cf3659503b6d79f5e7554eb012f824181d2ee02281c3dba44e"
Nov 09 11:07:42 ubuntu-s-2vcpu-4gb-intel-fra1-01 kubelet[1056728]: I1109 11:07:42.027295 1056728 docker_sandbox.go:401] "Failed to read pod IP from plugin/docker" err="Couldn't find network status for kubernetes-dashboard/kubernetes-dashboard-654cf69797-n4d2t through plugin: invalid network status for"
Nov 09 11:07:42 ubuntu-s-2vcpu-4gb-intel-fra1-01 kubelet[1056728]: I1109 11:07:42.107451 1056728 pod_container_deletor.go:79] "Container not found in pod's containers" containerID="2fd6ea861bf4a40830f8d5d3580b4c5ea3ee445674ca9bb20cf31cfc6f4ac0bc"
Nov 09 11:07:42 ubuntu-s-2vcpu-4gb-intel-fra1-01 kubelet[1056728]: I1109 11:07:42.107751 1056728 docker_sandbox.go:401] "Failed to read pod IP from plugin/docker" err="Couldn't find network status for kubernetes-dashboard/dashboard-metrics-scraper-5594458c94-5d9kh through plugin: invalid network status for"
Nov 09 11:07:43 ubuntu-s-2vcpu-4gb-intel-fra1-01 kubelet[1056728]: I1109 11:07:43.124580 1056728 docker_sandbox.go:401] "Failed to read pod IP from plugin/docker" err="Couldn't find network status for kubernetes-dashboard/dashboard-metrics-scraper-5594458c94-5d9kh through plugin: invalid network status for"
Nov 09 11:07:43 ubuntu-s-2vcpu-4gb-intel-fra1-01 kubelet[1056728]: I1109 11:07:43.163580 1056728 docker_sandbox.go:401] "Failed to read pod IP from plugin/docker" err="Couldn't find network status for kubernetes-dashboard/kubernetes-dashboard-654cf69797-n4d2t through plugin: invalid network status for"
Nov 09 11:07:43 ubuntu-s-2vcpu-4gb-intel-fra1-01 kubelet[1056728]: E1109 11:07:43.954293 1056728 cadvisor_stats_provider.go:415] "Partial failure issuing cadvisor.ContainerInfoV2" err="partial failures: [\"/kubepods/besteffort/podaee4b048-badc-47a6-848a-1d0f1f284aa0\": RecentStats: unable to find data in memory cache]"
Nov 09 11:08:16 ubuntu-s-2vcpu-4gb-intel-fra1-01 kubelet[1056728]: I1109 11:08:16.046338 1056728 topology_manager.go:200] "Topology Admit Handler"
Nov 09 11:08:16 ubuntu-s-2vcpu-4gb-intel-fra1-01 kubelet[1056728]: W1109 11:08:16.068080 1056728 container.go:586] Failed to update stats for container "/kubepods/burstable/podce45aee3-c47d-45b1-bbc2-d7575b1c100f": /sys/fs/cgroup/cpuset/kubepods/burstable/podce45aee3-c47d-45b1-bbc2-d7575b1c100f/cpuset.cpus found to be empty, continuing to push stats
Nov 09 11:08:16 ubuntu-s-2vcpu-4gb-intel-fra1-01 kubelet[1056728]: I1109 11:08:16.109249 1056728 reconciler.go:224] "operationExecutor.VerifyControllerAttachedVolume started for volume \"webhook-cert\" (UniqueName: \"kubernetes.io/secret/ce45aee3-c47d-45b1-bbc2-d7575b1c100f-webhook-cert\") pod \"ingress-nginx-controller-5f66978484-w8qm7\" (UID: \"ce45aee3-c47d-45b1-bbc2-d7575b1c100f\") "
Nov 09 11:08:16 ubuntu-s-2vcpu-4gb-intel-fra1-01 kubelet[1056728]: I1109 11:08:16.109322 1056728 reconciler.go:224] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-zx8xc\" (UniqueName: \"kubernetes.io/projected/ce45aee3-c47d-45b1-bbc2-d7575b1c100f-kube-api-access-zx8xc\") pod \"ingress-nginx-controller-5f66978484-w8qm7\" (UID: \"ce45aee3-c47d-45b1-bbc2-d7575b1c100f\") "
Nov 09 11:08:17 ubuntu-s-2vcpu-4gb-intel-fra1-01 kubelet[1056728]: I1109 11:08:17.121968 1056728 docker_sandbox.go:401] "Failed to read pod IP from plugin/docker" err="Couldn't find network status for ingress-nginx/ingress-nginx-controller-5f66978484-w8qm7 through plugin: invalid network status for"
Nov 09 11:08:17 ubuntu-s-2vcpu-4gb-intel-fra1-01 kubelet[1056728]: I1109 11:08:17.124556 1056728 pod_container_deletor.go:79] "Container not found in pod's containers" containerID="1de09b1aef47ec28708bb7ee8cad87e709062ce92f63ea0db9b58a9475f1452c"
Nov 09 11:08:18 ubuntu-s-2vcpu-4gb-intel-fra1-01 kubelet[1056728]: I1109 11:08:18.134600 1056728 docker_sandbox.go:401] "Failed to read pod IP from plugin/docker" err="Couldn't find network status for ingress-nginx/ingress-nginx-controller-5f66978484-w8qm7 through plugin: invalid network status for"
Nov 09 11:08:24 ubuntu-s-2vcpu-4gb-intel-fra1-01 kubelet[1056728]: E1109 11:08:24.113103 1056728 cadvisor_stats_provider.go:415] "Partial failure issuing cadvisor.ContainerInfoV2" err="partial failures: [\"/kubepods/burstable/podce45aee3-c47d-45b1-bbc2-d7575b1c100f\": RecentStats: unable to find data in memory cache]"
Nov 09 11:08:34 ubuntu-s-2vcpu-4gb-intel-fra1-01 kubelet[1056728]: E1109 11:08:34.146783 1056728 cadvisor_stats_provider.go:415] "Partial failure issuing cadvisor.ContainerInfoV2" err="partial failures: [\"/kubepods/burstable/podce45aee3-c47d-45b1-bbc2-d7575b1c100f\": RecentStats: unable to find data in memory cache]"
Nov 09 11:08:47 ubuntu-s-2vcpu-4gb-intel-fra1-01 kubelet[1056728]: I1109 11:08:47.677370 1056728 reconciler.go:196] "operationExecutor.UnmountVolume started for volume \"kube-api-access-j5lk7\" (UniqueName: \"kubernetes.io/projected/f8bb9d8d-0320-4c18-803f-c4f934e6a19b-kube-api-access-j5lk7\") pod \"f8bb9d8d-0320-4c18-803f-c4f934e6a19b\" (UID: \"f8bb9d8d-0320-4c18-803f-c4f934e6a19b\") "
Nov 09 11:08:47 ubuntu-s-2vcpu-4gb-intel-fra1-01 kubelet[1056728]: I1109 11:08:47.677461 1056728 reconciler.go:196] "operationExecutor.UnmountVolume started for volume \"webhook-cert\" (UniqueName: \"kubernetes.io/secret/f8bb9d8d-0320-4c18-803f-c4f934e6a19b-webhook-cert\") pod \"f8bb9d8d-0320-4c18-803f-c4f934e6a19b\" (UID: \"f8bb9d8d-0320-4c18-803f-c4f934e6a19b\") "
Nov 09 11:08:47 ubuntu-s-2vcpu-4gb-intel-fra1-01 kubelet[1056728]: I1109 11:08:47.688660 1056728 operation_generator.go:866] UnmountVolume.TearDown succeeded for volume "kubernetes.io/secret/f8bb9d8d-0320-4c18-803f-c4f934e6a19b-webhook-cert" (OuterVolumeSpecName: "webhook-cert") pod "f8bb9d8d-0320-4c18-803f-c4f934e6a19b" (UID: "f8bb9d8d-0320-4c18-803f-c4f934e6a19b"). InnerVolumeSpecName "webhook-cert". PluginName "kubernetes.io/secret", VolumeGidValue ""
Nov 09 11:08:47 ubuntu-s-2vcpu-4gb-intel-fra1-01 kubelet[1056728]: I1109 11:08:47.697597 1056728 operation_generator.go:866] UnmountVolume.TearDown succeeded for volume "kubernetes.io/projected/f8bb9d8d-0320-4c18-803f-c4f934e6a19b-kube-api-access-j5lk7" (OuterVolumeSpecName: "kube-api-access-j5lk7") pod "f8bb9d8d-0320-4c18-803f-c4f934e6a19b" (UID: "f8bb9d8d-0320-4c18-803f-c4f934e6a19b"). InnerVolumeSpecName "kube-api-access-j5lk7". PluginName "kubernetes.io/projected", VolumeGidValue ""
Nov 09 11:08:47 ubuntu-s-2vcpu-4gb-intel-fra1-01 kubelet[1056728]: I1109 11:08:47.778103 1056728 reconciler.go:319] "Volume detached for volume \"webhook-cert\" (UniqueName: \"kubernetes.io/secret/f8bb9d8d-0320-4c18-803f-c4f934e6a19b-webhook-cert\") on node \"ubuntu-s-2vcpu-4gb-intel-fra1-01\" DevicePath \"\""
Nov 09 11:08:47 ubuntu-s-2vcpu-4gb-intel-fra1-01 kubelet[1056728]: I1109 11:08:47.778156 1056728 reconciler.go:319] "Volume detached for volume \"kube-api-access-j5lk7\" (UniqueName: \"kubernetes.io/projected/f8bb9d8d-0320-4c18-803f-c4f934e6a19b-kube-api-access-j5lk7\") on node \"ubuntu-s-2vcpu-4gb-intel-fra1-01\" DevicePath \"\""
Nov 09 11:08:48 ubuntu-s-2vcpu-4gb-intel-fra1-01 kubelet[1056728]: I1109 11:08:48.492079 1056728 scope.go:110] "RemoveContainer" containerID="bb18deef804c293f35d6346ec1f36e0adadc679108eb14ee3cf1fbb88330d2a4"
Nov 09 11:08:48 ubuntu-s-2vcpu-4gb-intel-fra1-01 kubelet[1056728]: I1109 11:08:48.944635 1056728 kubelet_volumes.go:160] "Cleaned up orphaned pod volumes dir" podUID=f8bb9d8d-0320-4c18-803f-c4f934e6a19b path="/var/lib/kubelet/pods/f8bb9d8d-0320-4c18-803f-c4f934e6a19b/volumes"

* 
* ==> kubernetes-dashboard [1b276a76bb2c] <==
* 2021/11/09 11:07:42 Starting overwatch
2021/11/09 11:07:42 Using namespace: kubernetes-dashboard
2021/11/09 11:07:42 Using in-cluster config to connect to apiserver
2021/11/09 11:07:42 Using secret token for csrf signing
2021/11/09 11:07:42 Initializing csrf token from kubernetes-dashboard-csrf secret
2021/11/09 11:07:42 Empty token. Generating and storing in a secret kubernetes-dashboard-csrf
2021/11/09 11:07:42 Successful initial request to the apiserver, version: v1.22.3
2021/11/09 11:07:42 Generating JWE encryption key
2021/11/09 11:07:42 New synchronizer has been registered: kubernetes-dashboard-key-holder-kubernetes-dashboard. Starting
2021/11/09 11:07:42 Starting secret synchronizer for kubernetes-dashboard-key-holder in namespace kubernetes-dashboard
2021/11/09 11:07:42 Initializing JWE encryption key from synchronized object
2021/11/09 11:07:42 Creating in-cluster Sidecar client
2021/11/09 11:07:42 Metric client health check failed: the server is currently unable to handle the request (get services dashboard-metrics-scraper). Retrying in 30 seconds.
2021/11/09 11:07:42 Serving insecurely on HTTP port: 9090
2021/11/09 11:08:12 Successful request to sidecar

* 
* ==> storage-provisioner [41313c7f0c94] <==
* I1109 11:03:46.418240       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I1109 11:03:46.443529       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I1109 11:03:46.444784       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I1109 11:03:46.478939       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I1109 11:03:46.482358       1 event.go:282] Event(v1.ObjectReference{Kind:"Endpoints", Namespace:"kube-system", Name:"k8s.io-minikube-hostpath", UID:"48968e9e-2fd9-48f5-a7f9-1fa9de077b2b", APIVersion:"v1", ResourceVersion:"450", FieldPath:""}): type: 'Normal' reason: 'LeaderElection' ubuntu-s-2vcpu-4gb-intel-fra1-01_b94f6fcb-5515-44cc-b5dc-558880e0a71e became leader
I1109 11:03:46.482415       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_ubuntu-s-2vcpu-4gb-intel-fra1-01_b94f6fcb-5515-44cc-b5dc-558880e0a71e!
I1109 11:03:46.590586       1 controller.go:884] Started provisioner controller k8s.io/minikube-hostpath_ubuntu-s-2vcpu-4gb-intel-fra1-01_b94f6fcb-5515-44cc-b5dc-558880e0a71e!

